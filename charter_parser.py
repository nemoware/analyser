# origin: charter_parser.py

from contract_parser import _find_most_relevant_paragraph, find_value_sign_currency_attention
from embedding_tools import AbstractEmbedder
from hyperparams import HyperParameters
from legal_docs import LegalDocument, LegalDocumentExt, remap_attention_vector, ContractValue, \
  tokenize_doc_into_sentences_map, embedd_sentences, map_headlines_to_patterns
from ml_tools import *
from parsing import ParsingContext
from patterns import build_sentence_patterns, PATTERN_DELIMITER
from structures import *
from transaction_values import number_re

WARN = '\033[1;31m'

competence_headline_pattern_prefix = 'headline'


class CharterDocument(LegalDocumentExt):

  def __init__(self, doc: LegalDocument):
    super().__init__(doc)
    if doc is not None:
      self.__dict__ = doc.__dict__

    self.sentence_map: TextMap = None
    self.sentences_embeddings = None

    self.distances_per_sentence_pattern_dict = {}

    self.charity_tags = []
    self.org_levels = []
    self.constraint_tags = []
    self.org_level_tags = []

    self.margin_values: [ContractValue] = []

  def get_tags(self) -> [SemanticTag]:
    tags = []
    tags += self.charity_tags
    tags += self.org_levels
    tags += self.org_level_tags
    tags += self.constraint_tags

    for mv in self.margin_values:
      tags += mv.as_list()

    return tags


""" â¤ï¸ == GOOD CharterDocumentParser  ====================================== """


class CharterParser(ParsingContext):
  strs_subjects_patterns = {

    CharterSubject.Deal: [
      'Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÑÐ´ÐµÐ»Ð¾Ðº'
    ],

    CharterSubject.Charity: [
      'Ð¿Ð¾Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð½Ð° Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸Ð»Ð¸ Ð±Ð»Ð°Ð³Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ†ÐµÐ»Ð¸',
      'Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ð¹ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸',
      'ÑÐ´ÐµÐ»Ð¾Ðº Ð´Ð°Ñ€ÐµÐ½Ð¸Ñ',
      'Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² ÑÐ¿Ð¾Ð½ÑÐ¾Ñ€ÑÐºÐ¾Ð³Ð¾ Ð¸ Ð±Ð»Ð°Ð³Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð°',
      'Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð² Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ',
      'Ð¼ÐµÐ½Ñ‹, Ð´Ð°Ñ€ÐµÐ½Ð¸Ñ, Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ðµ Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ '
    ],

    CharterSubject.Lawsuit: [
      'Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ðµ/ÑƒÑ€ÐµÐ³ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð»ÑŽÐ±Ñ‹Ñ… ÑÑƒÐ´ÐµÐ±Ð½Ñ‹Ñ… ÑÐ¿Ð¾Ñ€Ð¾Ð² Ð¸ Ñ€Ð°Ð·Ð±Ð¸Ñ€Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²',
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¸ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑÑƒÐ´ÐµÐ±Ð½Ð¾Ð¼Ñƒ Ð´ÐµÐ»Ñƒ Ñ Ñ†ÐµÐ½Ð¾Ð¹ Ð¸ÑÐºÐ° '
    ],

    CharterSubject.RealEstate: [
      'ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´Ð°ÐµÐ¼Ð¾Ð³Ð¾ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°',
      'ÑÐ´ÐµÐ»ÐºÐ¸ Ñ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð¼ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°'
    ],

    CharterSubject.Insurance: [
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ',
      'Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ'
      'ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ ÑÐ´ÐµÐ»Ð¾Ðº ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ'
    ],

    CharterSubject.Consulting: [
      'Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð° Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑƒÑÐ»ÑƒÐ³',
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð°Ð³ÐµÐ½Ñ‚ÑÐºÐ¾Ð³Ð¾ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð°',
      'ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð° Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑƒÑÐ»ÑƒÐ³ Ð¸Ð»Ð¸ Ð°Ð³ÐµÐ½Ñ‚ÑÐºÐ¾Ð³Ð¾ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð°',
      'Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ñƒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑƒÑÐ»ÑƒÐ³ '
    ],

    CharterSubject.Other: [
      'Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾ Ð²Ð·Ñ‹ÑÐºÐ°Ð½Ð¸Ð¸ Ñ Ð“ÐµÐ½ÐµÑ€Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð° ÑƒÐ±Ñ‹Ñ‚ÐºÐ¾Ð²',
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² Ð¾Ð± Ð¾Ñ‚ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð¼ , Ð½Ð¾Ð²Ð°Ñ†Ð¸Ð¸ Ð¸/Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¸Ð¸ Ð´Ð¾Ð»Ð³Ð° , Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² Ð¾Ð± ÑƒÑÑ‚ÑƒÐ¿ÐºÐµ Ð¿Ñ€Ð°Ð²Ð° Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ðµ Ð´Ð¾Ð»Ð³Ð°',
      'Ð¾ Ð²Ñ‹Ð´Ð°Ñ‡Ðµ Ð¸Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð¼ Ð²ÐµÐºÑÐµÐ»ÐµÐ¹ , Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²Ðµ Ð¿Ð¾ Ð½Ð¸Ð¼ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ð½Ð°Ð´Ð¿Ð¸ÑÐµÐ¹ , Ð°Ð²Ð°Ð»ÐµÐ¹ , Ð¿Ð»Ð°Ñ‚ÐµÐ¶ÐµÐ¹',
      'Ð½ÐµÑ†ÐµÐ»ÐµÐ²Ð¾Ðµ Ñ€Ð°ÑÑ…Ð¾Ð´Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð¼ Ð´ÐµÐ½ÐµÐ¶Ð½Ñ‹Ñ… ÑÑ€ÐµÐ´ÑÑ‚Ð²'
    ]

  }

  def _make_patterns(self):

    comp_str_pat = []
    comp_str_pat += [[PATTERN_DELIMITER.join([competence_headline_pattern_prefix, ol.name]), ol.display_string] for ol
                     in OrgStructuralLevel]
    comp_str_pat += [[PATTERN_DELIMITER.join([competence_headline_pattern_prefix, 'comp', 'q', ol.name]),
                      "Ðº ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸ " + ol.display_string + ' Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹'] for ol in
                     OrgStructuralLevel]
    comp_str_pat += [[PATTERN_DELIMITER.join([competence_headline_pattern_prefix, 'comp', ol.name]),
                      "ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸ " + ol.display_string] for ol in OrgStructuralLevel]

    self.patterns_dict = comp_str_pat

  def __init__(self, embedder: AbstractEmbedder, elmo_embedder_default: AbstractEmbedder):
    ParsingContext.__init__(self, embedder)

    self.patterns_dict = []

    self.elmo_embedder_default: AbstractEmbedder = elmo_embedder_default

    self._make_patterns()
    patterns_te = [p[1] for p in self.patterns_dict]

    self.patterns_embeddings = elmo_embedder_default.embedd_strings(patterns_te)
    self.subj_patterns_embeddings = embedd_charter_subject_patterns(CharterParser.strs_subjects_patterns,
                                                                    elmo_embedder_default)

  def ebmedd(self, doc: CharterDocument):
    doc.sentence_map = tokenize_doc_into_sentences_map(doc, 200)

    ### âš™ï¸ðŸ”® SENTENCES embedding
    doc.sentences_embeddings = embedd_sentences(doc.sentence_map, self.elmo_embedder_default)

    doc.distances_per_sentence_pattern_dict = calc_distances_per_pattern_dict(doc.sentences_embeddings,
                                                                              self.patterns_dict,
                                                                              self.patterns_embeddings)

  def analyse(self, charter: CharterDocument):
    patterns_by_headers = self.map_charter_headlines_to_patterns(charter)

    charter.margin_values = []
    charter.constraint_tags = []
    charter.charity_tags = []
    # --------------
    filtered = [p_mapping for p_mapping in patterns_by_headers if p_mapping]
    for p_mapping in filtered:
      paragraph = p_mapping[4]
      org_level_name = p_mapping[1].split('/')[-1]
      org_level = OrgStructuralLevel[org_level_name]
      subdoc = charter.subdoc_slice(paragraph.body.as_slice())

      parent_org_level_tag = SemanticTag(org_level.name, org_level, paragraph.body.span)
      charter.org_levels.append(parent_org_level_tag)

      constraint_tags, values = self.attribute_charter_subjects(subdoc, self.subj_patterns_embeddings,
                                                                parent_org_level_tag)

      for value in values:
        value += subdoc.start

      for constraint_tag in constraint_tags:
        constraint_tag.offset(subdoc.start)

      charter.margin_values += values
      charter.constraint_tags += constraint_tags

      # charity_subj_av_words = subject_attentions_map[CharterSubject.Charity]['words']
      # charity_tag = find_charity_paragraphs(parent_org_level_tag, subdoc, (charity_subj_av_words + consent_words) / 2)
      # # print(charity_tag)
      # if charity_tag is not None:
      #   charter.charity_tags.append(charity_tag)

  def attribute_charter_subjects(self, subdoc: LegalDocumentExt, emb_subj_patterns, parent_org_level_tag: SemanticTag):
    """
    :param subdoc:
    :param emb_subj_patterns:

          emb_subj_patterns[subj] = {
            'patterns':patterns,
            'embedding':patterns_emb
          }

    :return:
    """

    # ---------------
    subject_attentions_map = get_charter_subj_attentions(subdoc, emb_subj_patterns)
    values: List[ContractValue] = find_value_sign_currency_attention(subdoc, None)
    # -------------------

    # collect sentences having constraint values
    sentence_spans = []
    for value in values:
      sentence_span = subdoc.tokens_map.sentence_at_index(value.parent.span[0], return_delimiters=True)
      if sentence_span not in sentence_spans:
        sentence_spans.append(sentence_span)
    sentence_spans = merge_colliding_spans(sentence_spans, eps=1)

    # ---
    # attribute sentences to subject
    constraint_tags = []

    for span in sentence_spans:

      max_confidence = 0
      best_subject = CharterSubject.Other

      for subj in subject_attentions_map.keys():
        av = subject_attentions_map[subj]['words']

        confidence_region = av[span[0]:span[1]]
        confidence = estimate_confidence_by_mean_top_non_zeros(confidence_region)

        if confidence > max_confidence:
          max_confidence = confidence
          best_subject = subj

      #
      constraint_tag = SemanticTag(f'{best_subject.name}', best_subject, span, parent=parent_org_level_tag)
      # constraint_tag.offset(subdoc.start)
      constraint_tags.append(constraint_tag)

      # nest values
      for value in values:
        # value+=subdoc.start
        if constraint_tag.is_nested(value.parent.span):
          value.parent.set_parent_tag(constraint_tag)

    return constraint_tags, values

  def map_charter_headlines_to_patterns(self, charter: LegalDocument):
    charter_parser = self

    p_suffices = [ol.name for ol in OrgStructuralLevel]
    p_suffices += [PATTERN_DELIMITER.join(['comp', ol.name]) for ol in OrgStructuralLevel]
    p_suffices += [PATTERN_DELIMITER.join(['comp', 'q', ol.name]) for ol in OrgStructuralLevel]

    map_, distances = map_headlines_to_patterns(charter,
                                                charter_parser.patterns_dict,
                                                charter_parser.patterns_embeddings,
                                                charter_parser.elmo_embedder_default,
                                                competence_headline_pattern_prefix,
                                                p_suffices)

    return map_


def put_if_better(destination: dict, key, x, is_better: staticmethod):
  if key in destination:
    if is_better(x, destination[key]):
      destination[key] = x
  else:
    destination[key] = x


def split_by_number_2(tokens: List[str], attention: FixedVector, threshold) -> (
        List[List[str]], List[int], List[slice]):
  indexes = []
  last_token_is_number = False
  for i in range(len(tokens)):

    if attention[i] > threshold and len(number_re.findall(tokens[i])) > 0:
      if not last_token_is_number:
        indexes.append(i)
      last_token_is_number = True
    else:
      last_token_is_number = False

  text_fragments = []
  ranges: List[slice] = []
  if len(indexes) > 0:
    for i in range(1, len(indexes)):
      _slice = slice(indexes[i - 1], indexes[i])
      text_fragments.append(tokens[_slice])
      ranges.append(_slice)

    text_fragments.append(tokens[indexes[-1]:])
    ranges.append(slice(indexes[-1], len(tokens)))
  return text_fragments, indexes, ranges


def embedd_charter_subject_patterns(patterns_dict, embedder: AbstractEmbedder):
  emb_subj_patterns = {}
  for subj in patterns_dict.keys():
    strings = patterns_dict[subj]
    prefix = PATTERN_DELIMITER.join(['subject', subj.name])

    emb_subj_patterns[subj] = {
      'patterns': build_sentence_patterns(strings, prefix, subj),
      'embedding': embedder.embedd_strings(strings)
    }

  return emb_subj_patterns


def get_charter_subj_attentions(subdoc: LegalDocumentExt, emb_subj_patterns):
  _distances_per_subj = {}

  for subj in emb_subj_patterns.keys():
    patterns_distances = calc_distances_per_pattern_dict(subdoc.sentences_embeddings,
                                                         emb_subj_patterns[subj]['patterns'],
                                                         emb_subj_patterns[subj]['embedding'])

    prefix = PATTERN_DELIMITER.join(['subject', subj.name])

    subj_av = relu(max_exclusive_pattern_by_prefix(patterns_distances, prefix), 0.6)
    subj_av_words = remap_attention_vector(subj_av, subdoc.sentence_map, subdoc.tokens_map)

    _distances_per_subj[subj] = {
      'words': subj_av_words,
      'sentences': subj_av,
    }
  return _distances_per_subj


def find_charity_paragraphs(parent_org_level_tag: SemanticTag, subdoc: LegalDocument,
                            charity_subject_attention: FixedVector):
  paragraph_span, confidence, paragraph_attention_vector = _find_most_relevant_paragraph(subdoc,
                                                                                         charity_subject_attention,
                                                                                         min_len=20,
                                                                                         return_delimiters=False)

  if confidence > HyperParameters.charter_charity_attention_confidence:
    subject_tag = SemanticTag(CharterSubject.Charity.name, CharterSubject.Charity.name, paragraph_span,
                              parent=parent_org_level_tag)
    subject_tag.offset(subdoc.start)
    subject_tag.confidence = confidence
    return subject_tag
