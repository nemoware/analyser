import re
import warnings
from enum import Enum
from typing import Iterator

from pyjarowinkler import distance

from analyser.attributes import to_json
from analyser.contract_agents import complete_re as agents_re, find_org_names, ORG_LEVELS_re, find_org_names_raw, \
  ContractAgent, _rename_org_tags, protocol_caption_complete_re, protocol_caption_complete_re_ignore_case
from analyser.doc_dates import find_document_date
from analyser.doc_numbers import document_number_c, find_document_number_in_subdoc
from analyser.documents import sentences_attention_to_words
from analyser.embedding_tools import AbstractEmbedder
from analyser.hyperparams import HyperParameters
from analyser.legal_docs import LegalDocument, ContractValue, ParserWarnings, \
  LegalDocumentExt
from analyser.ml_tools import SemanticTag, calc_distances_per_pattern_dict, max_exclusive_pattern_by_prefix, relu, \
  sum_probabilities, best_above, smooth_safe, spans_between_non_zero_attention, \
  FixedVector, estimate_confidence_by_mean_top_non_zeros, SemanticTagBase, max_confident_tag
from analyser.parsing import ParsingContext, AuditContext, find_value_sign_currency_attention
from analyser.patterns import AbstractPatternFactory, FuzzyPattern, create_value_negation_patterns, \
  create_value_patterns
from analyser.schemas import ProtocolSchema, AgendaItem
from analyser.structures import ORG_LEVELS_names, OrgStructuralLevel
from analyser.text_normalize import r_group, r_quoted
from analyser.text_tools import is_long_enough, span_len
from analyser.transaction_values import complete_re as values_re

something = r'(\s*.{1,100}\s*)'
itog1 = r_group(r'\n' + r_group(r'Ð¸Ñ‚Ð¾Ð³Ð¸\s*Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð°Ð½Ð¸Ñ' + '|' + r'Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹\s*Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð°Ð½Ð¸Ñ') + r"[:\n]?")

_number_of_votes = r'(\s*[-: ]\s*)([0-9]|(Ð½ÐµÑ‚)|[_]{1,10})[.;]*\s*'
r_votes_za = r_group(r_quoted('Ð·Ð°') + _number_of_votes)
r_votes_pr = r_group(r_quoted('Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²') + _number_of_votes)
r_votes_vo = r_group(r_quoted('Ð²Ð¾Ð·Ð´ÐµÑ€Ð¶Ð°Ð»ÑÑ') + _number_of_votes)

protocol_votes_ = r_group(itog1 + something) + r_group(r_votes_za + r_votes_pr + r_votes_vo)
protocol_votes_re = re.compile(protocol_votes_, re.IGNORECASE | re.UNICODE)


class ProtocolAV(Enum):
  '''AV for Attention Vecotrs'''
  bin_votes_attention = 1
  relu_deal_approval = 2
  digits_attention = 3
  relu_value_attention_vector = 4


class ProtocolDocument(LegalDocumentExt):

  def __init__(self, doc: LegalDocument = None):
    super().__init__(doc)

    if doc is not None:
      # self.__dict__ = {**super().__dict__, **doc.__dict__}
      self.__dict__.update(doc.__dict__)

    self.agenda_questions: [SemanticTag] = []
    self.margin_values: [ContractValue] = []
    self.contract_numbers: [SemanticTag] = []

    self.attributes_tree = ProtocolSchema()

  def get_org_tags(self) -> [SemanticTag]:
    warnings.warn("please switch to attributes_tree struktur", DeprecationWarning)
    org = self.attributes_tree.org
    if org is not None:
      return _rename_org_tags([org], prefix="", start_from=1)

    return []

  org_tags = property(get_org_tags)

  def get_agents_tags(self) -> [SemanticTag]:
    warnings.warn("please switch to attributes_tree struktur", DeprecationWarning)
    res = []
    for ai in self.attributes_tree.agenda_items:
      parent = ai._legacy_tag_ref
      if ai.contract is not None:

        _tags = _rename_org_tags(ai.contract.orgs, prefix='contract_agent_', start_from=2)
        for t in _tags:
          t._parent_tag = parent

    return res

  agents_tags = property(get_agents_tags)

  def get_org_level(self) -> SemanticTagBase:
    return self.attributes_tree.structural_level

  def set_org_level(self, structural_level):
    self.attributes_tree.structural_level = structural_level

  org_level = property(get_org_level, set_org_level)

  def get_date(self) -> SemanticTagBase:
    return self.attributes_tree.date

  def set_date(self, date):
    self.attributes_tree.date = date

  date = property(get_date, set_date)

  def get_tags(self) -> [SemanticTag]:
    warnings.warn("please switch to attributes_tree struktur", DeprecationWarning)
    tags = []
    if self.date is not None:
      tags.append(self.date)

    tags += self.org_tags
    tags += [self.org_level]
    tags += self.agents_tags
    tags += self.agenda_questions
    tags += self.contract_numbers
    for mv in self.margin_values:
      tags += mv.as_list()

    return tags

  def to_json_obj(self) -> dict:
    j: dict = super().to_json_obj()
    _attributes_tree_dict, _ = to_json(self.attributes_tree)
    j['attributes_tree'] = {"protocol": _attributes_tree_dict}
    return j


ProtocolDocument4 = ProtocolDocument  # aliasing #todo: remove it #still needed for old unit tests


class ProtocolParser(ParsingContext):
  patterns_dict = [
    ['sum_max1', 'ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 0 Ð¼Ð»Ð½. Ñ‚Ñ‹Ñ. Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½Ð¾Ð² Ñ‚Ñ‹ÑÑÑ‡ Ñ€ÑƒÐ±Ð»ÐµÐ¹ Ð´Ð¾Ð»Ð»Ð°Ñ€Ð¾Ð² ÐºÐ¾Ð¿ÐµÐµÐº ÐµÐ²Ñ€Ð¾'],

    # ['solution_1','Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ, Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾Ðµ Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ:'],
    # ['solution_2','Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ñ‹ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ:'],

    ['not_value_1', 'Ñ€Ð°Ð·Ð¼ÐµÑ€ ÑƒÑÑ‚Ð°Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ°Ð¿Ð¸Ñ‚Ð°Ð»Ð° 0 Ñ€ÑƒÐ±Ð»ÐµÐ¹'],
    ['not_value_2', 'Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¸ ÑÐµÐºÑ€ÐµÑ‚Ð°Ñ€Ñ'],

    ['agenda_end_1', 'ÐºÐ²Ð¾Ñ€ÑƒÐ¼ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ Ð·Ð°ÑÐµÐ´Ð°Ð½Ð¸Ñ Ð¸ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ Ð¸Ð¼ÐµÐµÑ‚ÑÑ'],
    ['agenda_end_2', 'Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ Ð·Ð°ÑÐµÐ´Ð°Ð½Ð¸Ñ'],
    ['agenda_end_3', 'Ð¤Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ° Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ Ð·Ð°ÑÐµÐ´Ð°Ð½Ð¸Ñ:'],

    ['agenda_start_1', 'Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ° Ð´Ð½Ñ Ð·Ð°ÑÐµÐ´Ð°Ð½Ð¸Ñ'],
    ['agenda_start_2', 'ÐŸÐ¾Ð²ÐµÑÑ‚ÐºÐ° Ð´Ð½Ñ'],

    ['deal_approval_1', 'Ð¾Ð´Ð¾Ð±Ñ€Ð¸Ñ‚ÑŒ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ ÑÐ´ÐµÐ»ÐºÐ¸'],
    ['deal_approval_2', 'Ð¾Ð´Ð¾Ð±Ñ€Ð¸Ñ‚ÑŒ ÑÐ´ÐµÐ»ÐºÑƒ'],
    ['deal_approval_3', 'Ð´Ð°Ñ‚ÑŒ ÑÐ¾Ð³Ð»Ð°ÑÐ¸Ðµ Ð½Ð° Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð°'],
    ['deal_approval_4', 'Ð¿Ñ€Ð¸Ð½ÑÑ‚ÑŒ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÑÐ´ÐµÐ»ÐºÐ¸'],
    ['deal_approval_5', 'Ð¿Ñ€Ð¸Ð½ÑÑ‚ÑŒ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¹ ÑÐ´ÐµÐ»ÐºÐ¸'],
    ['deal_approval_6', 'Ð·Ð°ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€ Ð°Ñ€ÐµÐ½Ð´Ñ‹'],
    ['deal_approval_7', 'ÐžÐ´Ð¾Ð±Ñ€Ð¸Ñ‚ÑŒ ÑÐ´ÐµÐ»ÐºÑƒ, ÑÐ²ÑÐ·Ð°Ð½Ð½ÑƒÑŽ Ñ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸ÐµÐ¼ Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ¾Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ñ'],

    ['question_1', 'ÐŸÐ¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ â„– 0'],
    ['question_2', 'ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ Ð·Ð°ÑÐµÐ´Ð°Ð½Ð¸Ñ'],
    ['question_3', 'Ð ÐµÑˆÐµÐ½Ð¸Ðµ, Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾Ðµ Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ:'],
    ['question_4', 'Ð ÐµÑˆÐµÐ½Ð¸Ðµ, Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾Ðµ Ð¿Ð¾ 1 Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ð¾Ð²ÐµÑÑ‚ÐºÐ¸ Ð´Ð½Ñ:'],

    ['footers_1', 'Ð’Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ð²ÐµÐ´ÐµÐ½Ð¸Ñ Ð¸Ñ‚Ð¾Ð³Ð¾Ð² Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð°Ð½Ð¸Ñ'],
    ['footers_2', 'Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹:'],
    ['footers_3', 'ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð² Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ð» Ð¡ÐµÐºÑ€ÐµÑ‚Ð°Ñ€ÑŒ Ð¡Ð¾Ð²ÐµÑ‚Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²'],
    ['footers_4', 'ÐŸÑ€Ð¾Ñ‚Ð¾ÐºÐ¾Ð» ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½ Ð² 2-Ñ… ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ð°Ñ…']

  ]

  def __init__(self, embedder: AbstractEmbedder = None, sentence_embedder: AbstractEmbedder = None):
    ParsingContext.__init__(self, embedder, sentence_embedder)

    self._protocols_factory: ProtocolPatternFactory or None = None
    self._patterns_embeddings = None

  def get_patterns_embeddings(self):
    if self._patterns_embeddings is None:
      patterns_te = [p[1] for p in ProtocolParser.patterns_dict]
      self._patterns_embeddings = self.get_sentence_embedder().embedd_strings(patterns_te)

    return self._patterns_embeddings

  def get_protocols_factory(self):
    if self._protocols_factory is None:
      self._protocols_factory = ProtocolPatternFactory(self.get_embedder())

    return self._protocols_factory

  def embedd(self, doc: ProtocolDocument):

    ### âš™ï¸ðŸ”® SENTENCES embedding
    # if doc.sentence_map is None:
    #   doc.sentence_map = tokenize_doc_into_sentences_map(doc, HyperParameters.charter_sentence_max_len)
    doc.sentences_embeddings = self.get_sentence_embedder().embedd_strings(doc.sentence_map.tokens)

    ### âš™ï¸ðŸ”® WORDS Embedding
    doc.embedd_tokens(self.get_embedder())

    doc.calculate_distances_per_pattern(self.get_protocols_factory())
    # TODO: should be made in analysys phase, not on embedding
    doc.distances_per_sentence_pattern_dict = calc_distances_per_pattern_dict(doc.sentences_embeddings,
                                                                              self.patterns_dict,
                                                                              self.get_patterns_embeddings())

  def find_org_date_number(self, doc: ProtocolDocument, ctx: AuditContext) -> ProtocolDocument:
    """
    phase 1, before embedding TF, GPU, and things
    searching for attributes required for filtering
    :param charter:
    :return:
    """
    # doc.sentence_map = tokenize_doc_into_sentences_map(doc, 250)

    doc.org_level = max_confident_tag(list(find_org_structural_level(doc)))
    doc.attributes_tree.org = find_protocol_org_obj(doc)
    doc.date = find_document_date(doc)

    if doc.attributes_tree.org is not None:
      if doc.attributes_tree.org.name is None:
        doc.warn(ParserWarnings.org_name_not_found)

    if not doc.date:
      doc.warn(ParserWarnings.date_not_found)

    if not doc.org_level:
      doc.warn(ParserWarnings.org_struct_level_not_found)

    return doc

  def find_attributes(self, doc: ProtocolDocument, ctx: AuditContext = None) -> ProtocolDocument:

    self.find_org_date_number(doc, ctx)

    if doc.sentences_embeddings is None or doc.embeddings is None:
      self.embedd(doc)  # lazy embedding

    doc.agenda_questions = self.find_question_decision_sections(doc)
    doc.margin_values = self.find_margin_values(doc)
    doc.contract_numbers = self.find_contract_numbers(doc)
    # doc.agents_tags = list(self.find_agents_in_all_sections(doc, doc.agenda_questions, ctx.audit_subsidiary_name))

    # migrazzio:
    for aq in doc.agenda_questions:
      ai = AgendaItem()
      ai.span = aq.span
      ai.confidence = aq.confidence
      setattr(ai, '_legacy_tag_ref', aq)  # TODO: remove this shit, it must not go to DB
      # ai.__dict__['_legacy_tag_ref'] = aq
      doc.attributes_tree.agenda_items.append(ai)

      for mv in doc.margin_values:
        if mv.is_child_of(aq):
          ai.contract.price = mv.as_ContractPrice()

      for cn in doc.contract_numbers:
        if cn.is_child_of(aq):
          ai.contract.number = cn.clean_copy()

    self.find_orgs_in_agendas(doc, ctx.audit_subsidiary_name)
    self.validate(doc, ctx)
    return doc

  def validate(self, document: ProtocolDocument, ctx: AuditContext):

    if not document.agenda_questions:
      document.warn(ParserWarnings.protocol_agenda_not_found)

    if not document.margin_values and not document.agents_tags and not document.contract_numbers:
      document.warn(ParserWarnings.boring_agenda_questions)

    # TODO: add more warnings

  def find_orgs_in_agendas(self,
                           doc: ProtocolDocument,
                           audit_subsidiary_name: str):

    for ai in doc.attributes_tree.agenda_items:
      span = ai.span
      _subdoc = doc[span[0]:span[1]]

      all: [ContractAgent] = find_org_names_raw(_subdoc, max_names=10, parent=None, decay_confidence=False)
      all: [ContractAgent] = sorted(all, key=lambda a: a.name.value != audit_subsidiary_name)

      ai.contract.orgs = all

  def find_margin_values(self, doc) -> [ContractValue]:
    if ProtocolAV.relu_value_attention_vector.name not in doc.distances_per_pattern_dict:
      raise KeyError('call find_question_decision_sections first')

    values: [ContractValue] = []
    for agenda_question_tag in doc.agenda_questions:
      subdoc = doc[agenda_question_tag.as_slice()]
      relu_value_attention_vector = subdoc.distances_per_pattern_dict[ProtocolAV.relu_value_attention_vector.name]
      subdoc_values: [ContractValue] = find_value_sign_currency_attention(subdoc,
                                                                          relu_value_attention_vector,
                                                                          parent_tag=agenda_question_tag,
                                                                          absolute_spans=True)
      values += subdoc_values
      if len(subdoc_values) > 1:
        confidence = 1.0 / len(subdoc_values)

        for k, v in enumerate(subdoc_values):
          v *= confidence  # decrease confidence
          v.parent.kind = SemanticTag.number_key(v.parent.kind, k)

    return values

  def find_contract_numbers(self, doc) -> [ContractValue]:

    values = []
    for agenda_question_tag in doc.agenda_questions:
      subdoc = doc[agenda_question_tag.as_slice()]

      numbers = find_document_number_in_subdoc(subdoc, tagname='number', parent=agenda_question_tag)

      for k, v in enumerate(numbers):
        # v.parent = agenda_question_tag
        v.kind = SemanticTag.number_key(v.kind, k)
      values += numbers
    return values

  def collect_spans_having_votes(self, segments, textmap):
    warnings.warn("use TextMap.regex_attention", DeprecationWarning)
    """
    search for votes in each document segment
    collect only
    :param segments:
    :param textmap:
    :return:  segments with votes
    """
    for span in segments:
      subdoc = textmap.slice(span)
      protocol_votes = list(subdoc.finditer(protocol_votes_re))
      if protocol_votes:
        yield span

  def find_protocol_sections_edges(self, distances_per_pattern_dict):

    patterns = ['footers_', 'deal_approval_', 'question_']
    vv_ = []
    for p in patterns:
      v_ = max_exclusive_pattern_by_prefix(distances_per_pattern_dict, p)
      v_ = relu(v_, 0.55)
      vv_.append(v_)

    v_sections_attention = sum_probabilities(vv_)
    v_sections_attention = best_above(v_sections_attention, 0.55)
    return v_sections_attention

  def _get_value_attention_vector(self, doc: LegalDocument):
    s_value_attention_vector = max_exclusive_pattern_by_prefix(doc.distances_per_pattern_dict, 'sum_max_p_')

    doc.distances_per_pattern_dict['__max_value_av'] = s_value_attention_vector  # just for debugging
    not_value_av = max_exclusive_pattern_by_prefix(doc.distances_per_pattern_dict, 'not_sum_')

    not_value_av = smooth_safe(not_value_av, window_len=5)

    not_value_av = relu(not_value_av, 0.5)
    doc.distances_per_pattern_dict['__not_value_av'] = not_value_av  # just for debugging

    s_value_attention_vector -= not_value_av * 0.8
    s_value_attention_vector = relu(s_value_attention_vector, 0.3)
    return s_value_attention_vector

  def find_question_decision_sections(self, doc: ProtocolDocument) -> [SemanticTag]:

    # DEAL APPROVAL SENTENCES
    _v_deal_approval: FixedVector = max_exclusive_pattern_by_prefix(doc.distances_per_sentence_pattern_dict,
                                                                    'deal_approval_')
    _spans, deal_approval_av = sentences_attention_to_words(_v_deal_approval, doc.sentence_map, doc.tokens_map)
    deal_approval_relu_av: FixedVector = best_above(deal_approval_av, 0.5)

    # VOTES
    votes_av: FixedVector = doc.tokens_map.regex_attention(protocol_votes_re)

    # DOC NUMBERS
    numbers_av: FixedVector = doc.tokens_map.regex_attention(document_number_c)

    # DOC AGENTS orgs
    agents_av: FixedVector = doc.tokens_map.regex_attention(agents_re)

    # DOC MARGIN VALUES
    margin_values_av: FixedVector = self._get_value_attention_vector(doc)
    margin_values_v: FixedVector = doc.tokens_map.regex_attention(values_re)
    margin_values_v *= margin_values_av
    doc.distances_per_pattern_dict[ProtocolAV.relu_value_attention_vector.name] = margin_values_av

    # -----
    combined_av: FixedVector = sum_probabilities([
      deal_approval_relu_av,
      margin_values_v,
      agents_av / 2,
      votes_av / 2,
      numbers_av / 2])

    # TODO: this is exactly what we will get from NN out layer
    combined_av_norm: FixedVector = best_above(combined_av, 0.2)
    # --------------

    _protocol_sections_edges = self.find_protocol_sections_edges(doc.distances_per_sentence_pattern_dict)
    _question_spans_sent = spans_between_non_zero_attention(_protocol_sections_edges)
    question_spans_words = doc.sentence_map.remap_slices(_question_spans_sent, doc.tokens_map)

    agenda_questions = list(find_confident_spans(question_spans_words, combined_av_norm, 'agenda_item', 0.5))

    return agenda_questions


class ProtocolPatternFactory(AbstractPatternFactory):

  def create_pattern(self, pattern_name, ppp):
    _ppp = (ppp[0].lower(), ppp[1].lower(), ppp[2].lower())
    fp = FuzzyPattern(_ppp, pattern_name)
    self.patterns.append(fp)
    return fp

  def __init__(self, embedder):
    AbstractPatternFactory.__init__(self)

    create_value_negation_patterns(self)
    create_value_patterns(self)

    self.embedd(embedder)


def find_protocol_org_obj(protocol: ProtocolDocument) -> ContractAgent or None:
  _subdoc = protocol[0:HyperParameters.protocol_caption_max_size_words]
  orgs: [ContractAgent] = find_org_names_raw(_subdoc, max_names=1, regex=protocol_caption_complete_re,
                                             re_ignore_case=protocol_caption_complete_re_ignore_case)
  if len(orgs) == 0:
    return None

  return orgs[0]


def find_protocol_org(protocol: ProtocolDocument) -> [SemanticTag]:
  warnings.warn("please switch to find_protocol_org_obj", DeprecationWarning)

  ret = []
  _subdoc = protocol[0:HyperParameters.protocol_caption_max_size_words]
  _flat_list: [SemanticTag] = find_org_names(_subdoc,
                                             max_names=1,
                                             regex=protocol_caption_complete_re,
                                             re_ignore_case=protocol_caption_complete_re_ignore_case)

  nm = SemanticTag.find_by_kind(_flat_list, 'org-1-name')
  if nm is not None:
    ret.append(nm)
  else:
    protocol.warn(ParserWarnings.org_name_not_found)

  tp = SemanticTag.find_by_kind(_flat_list, 'org-1-type')
  if tp is not None:
    ret.append(tp)
  else:
    protocol.warn(ParserWarnings.org_type_not_found)
  return ret


def closest_name(pattern: str, knowns: [str]) -> (str, int):
  #
  min_distance = 0
  found = None
  for b in knowns:
    d = distance.get_jaro_distance(pattern, b, winkler=True, scaling=0.1)
    if d > min_distance:
      found = b
      min_distance = d

  return found, min_distance


def find_org_structural_level(doc: LegalDocument) -> Iterator[SemanticTag]:
  compiled_re = re.compile(ORG_LEVELS_re, re.MULTILINE | re.IGNORECASE | re.UNICODE)

  entity_type = 'org_structural_level'
  for m in re.finditer(compiled_re, doc.text):

    char_span = m.span(entity_type)
    span = doc.tokens_map.token_indices_by_char_range(char_span)
    val = doc.tokens_map.text_range(span)

    val, conf = closest_name(val, ORG_LEVELS_names)

    confidence = conf * (1.0 - (span[0] / len(doc)))  # relative distance from the beginning of the document
    if span_len(char_span) > 1 and is_long_enough(val):

      if confidence > HyperParameters.org_level_min_confidence:
        tag = SemanticTag(entity_type, OrgStructuralLevel.find_by_display_string(val), span)
        tag.confidence = confidence

        yield tag


def find_confident_spans(slices: [int], block_confidence: FixedVector, tag_name: str, threshold: float) -> Iterator[
  SemanticTag]:
  count = 0
  for _slice in slices:
    pv = block_confidence[_slice[0]:_slice[1]]
    confidence = estimate_confidence_by_mean_top_non_zeros(pv, 5)

    if confidence > threshold:
      count += 1
      st = SemanticTag(SemanticTag.number_key(tag_name, count), None, _slice)
      st.confidence = confidence
      yield (st)
