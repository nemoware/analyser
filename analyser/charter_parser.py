# origin: charter_parser.py
import warnings

import pandas as pd
from overrides import overrides
from pandas import DataFrame

from analyser.attributes import to_json
from analyser.contract_agents import find_org_names, ContractAgent, find_org_names_raw, _rename_org_tags
from analyser.doc_dates import find_document_date
from analyser.embedding_tools import AbstractEmbedder
from analyser.hyperparams import HyperParameters
from analyser.legal_docs import LegalDocumentExt, remap_attention_vector, embedd_sentences, LegalDocument, \
  ContractValue, ParserWarnings
from analyser.ml_tools import SemanticTag, calc_distances_per_pattern, merge_colliding_spans, TAG_KEY_DELIMITER, Spans, \
  FixedVector, span_to_slice, estimate_confidence_by_mean_top_non_zeros, calc_distances_per_pattern_dict, \
  max_exclusive_pattern_by_prefix, relu, attribute_patternmatch_to_index, SemanticTagBase
from analyser.parsing import ParsingContext, AuditContext, find_value_sign_currency_attention, \
  _find_most_relevant_paragraph
from analyser.patterns import build_sentence_patterns, PATTERN_DELIMITER
from analyser.schemas import CharterSchema, CharterStructuralLevel, Competence, Schema2LegacyListConverter
from analyser.structures import OrgStructuralLevel, ContractSubject

WARN = '\033[1;31m'

competence_headline_pattern_prefix = 'headline'

number_key = SemanticTag.number_key


class CharterDocument(LegalDocumentExt):

  def __init__(self, doc: LegalDocument = None):
    super().__init__(doc)
    if doc is not None:
      self.__dict__.update(doc.__dict__)
    self.attributes_tree = CharterSchema()

  def reset_attributes(self):
    """
    reset for preventing doubling tags
    :return:
    """
    self.attributes_tree = CharterSchema()

  def get_number(self) -> SemanticTagBase:
    return self.attributes_tree.number

  def set_number(self, number):
    self.attributes_tree.number = number

  def get_date(self) -> SemanticTagBase:
    warnings.warn("use attributes_tree.date", DeprecationWarning)
    return self.attributes_tree.date

  def set_date(self, date):
    warnings.warn("use attributes_tree.date", DeprecationWarning)
    self.attributes_tree.date = date

  date = property(get_date, set_date)
  number = property(get_number, set_number)

  def get_tags(self) -> [SemanticTag]:
    warnings.warn("please switch to attributes_tree struktur", DeprecationWarning)
    raise NotImplementedError('get_tags deleted forever')

  def get_org_tags(self) -> [SemanticTag]:
    warnings.warn("please switch to attributes_tree struktur", DeprecationWarning)
    org = self.attributes_tree.org
    if org is not None:
      return _rename_org_tags([org], prefix="", start_from=1)

    return []

  org_tags = property(get_org_tags)

  @overrides
  def to_json_obj(self) -> dict:
    j: dict = super().to_json_obj()
    _attributes_tree_dict, _ = to_json(self.attributes_tree)
    j['attributes_tree'] = {"charter": _attributes_tree_dict}
    return j

  @overrides
  def tags_to_json_attributes(self) -> dict:

    converter = Schema2LegacyListConverter()
    dest = {}
    converter.schema2list(dest, self.attributes_tree)

    return dest


def _make_org_level_patterns() -> pd.DataFrame:
  p = competence_headline_pattern_prefix  # just shortcut

  comp_str_pat = pd.DataFrame()

  for ol in OrgStructuralLevel:
    display_strings: [str] = ol.display_string
    for i, display_string in enumerate(display_strings):
      comp_str_pat[PATTERN_DELIMITER.join([str(i), p, ol.name])] = [display_string.lower()]
      comp_str_pat[PATTERN_DELIMITER.join([str(i), p, 'comp', 'q', ol.name])] = [
        f'Ðº ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸ {display_string} Ð¾Ñ‚Ð½Ð¾ÑÑÑ‚ÑÑ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹'.lower()]
      comp_str_pat[PATTERN_DELIMITER.join([str(i), p, 'comp', ol.name])] = f"ÐºÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ð¸ {display_string}".lower()

  _key = PATTERN_DELIMITER.join([p, 'comp', 'qr', OrgStructuralLevel.ShareholdersGeneralMeeting.name])
  comp_str_pat[_key] = ['ÐšÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ñ ÐžÐ±Ñ‰ÐµÐ³Ð¾ ÑÐ¾Ð±Ñ€Ð°Ð½Ð¸Ñ Ð°ÐºÑ†Ð¸Ð¾Ð½ÐµÑ€Ð¾Ð² ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°'.lower()]

  _key = PATTERN_DELIMITER.join([p, 'comp', 'qr', OrgStructuralLevel.BoardOfDirectors.name])
  comp_str_pat[_key] = ['ÐšÐ¾Ð¼Ð¿ÐµÑ‚ÐµÐ½Ñ†Ð¸Ñ Ð¡Ð¾Ð²ÐµÑ‚Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°'.lower()]

  _key = PATTERN_DELIMITER.join([p, 'comp', 'qr', OrgStructuralLevel.CEO.name])
  comp_str_pat[_key] = ['Ð•Ð´Ð¸Ð½Ð¾Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ€Ð³Ð°Ð½ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°'.lower()]

  return comp_str_pat.astype('str')


class CharterParser(ParsingContext):
  strs_subjects_patterns = {

    ContractSubject.Deal: [
      'Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÑÐ´ÐµÐ»Ð¾Ðº'
    ],

    ContractSubject.BigDeal: [
      'ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… ÑÐ´ÐµÐ»Ð¾Ðº',
      'ÑÐ¾Ð³Ð»Ð°ÑÐ¸Ðµ Ð½Ð° ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ Ð¾Ð´Ð¾Ð±Ñ€ÐµÐ½Ð¸Ðµ ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ñ… ÑÐ´ÐµÐ»Ð¾Ðº'
    ],

    ContractSubject.Charity: [
      "Ð¾Ð¿Ð»Ð°Ñ‚Ð° (Ð²ÑÑ‚Ñ€ÐµÑ‡Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ) Ð² Ð½ÐµÐ´ÐµÐ½ÐµÐ¶Ð½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ðµ",
      "Ð¿Ð¾Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ Ð½Ð° Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸Ð»Ð¸ Ð±Ð»Ð°Ð³Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ†ÐµÐ»Ð¸",
      "Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ð¹ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸",
      "ÑÐ´ÐµÐ»ÐºÐ¸ Ð´Ð°Ñ€ÐµÐ½Ð¸Ñ",
      'Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ðµ Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°',
      "Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ñ‹ ÑÐ¿Ð¾Ð½ÑÐ¾Ñ€ÑÐºÐ¾Ð³Ð¾ Ð¸ Ð±Ð»Ð°Ð³Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð°",
      "Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð² Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ",
      "Ð¼ÐµÐ½Ð°, Ð´Ð°Ñ€ÐµÐ½Ð¸Ðµ, Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾Ðµ Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ",
      'Ð²Ð½ÐµÑÐµÐ½Ð¸Ðµ Ð²ÐºÐ»Ð°Ð´Ð¾Ð² Ð¸Ð»Ð¸ Ð¿Ð¾Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð½Ð° Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸Ð»Ð¸ Ð±Ð»Ð°Ð³Ð¾Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ†ÐµÐ»Ð¸'
    ],

    ContractSubject.Lawsuit: [
      'ÑƒÑ€ÐµÐ³ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð»ÑŽÐ±Ñ‹Ñ… ÑÑƒÐ´ÐµÐ±Ð½Ñ‹Ñ… ÑÐ¿Ð¾Ñ€Ð¾Ð² Ð¸ Ñ€Ð°Ð·Ð±Ð¸Ñ€Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²',
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑÑƒÐ´ÐµÐ±Ð½Ð¾Ð¼Ñƒ Ð´ÐµÐ»Ñƒ Ñ Ñ†ÐµÐ½Ð¾Ð¹ Ð¸ÑÐºÐ° '
    ],

    ContractSubject.RealEstate: [
      'ÑÐ´ÐµÐ»ÐºÐ¸ Ñ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð¼ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°',
      'ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ñ‡ÑƒÐ¶Ð´Ð°ÐµÐ¼Ð¾Ð³Ð¾ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°',
      'ÑÐ´ÐµÐ»Ð¾Ðº ( Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð²Ð·Ð°Ð¸Ð¼Ð¾ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ñ… ÑÐ´ÐµÐ»Ð¾Ðº ) Ñ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð¼ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð°'
    ],

    ContractSubject.Insurance: [
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ',
      'Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ',
      'ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ ÑÐ´ÐµÐ»Ð¾Ðº ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ñ'
    ],

    ContractSubject.Service: [
      'Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ñ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑƒÑÐ»ÑƒÐ³',
      'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð°Ð³ÐµÐ½Ñ‚ÑÐºÐ¾Ð³Ð¾ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð°',
      'Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ñƒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑƒÑÐ»ÑƒÐ³'
    ],

    # CharterSubject.Other: [
    #   'Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾ Ð²Ð·Ñ‹ÑÐºÐ°Ð½Ð¸Ð¸ Ñ Ð“ÐµÐ½ÐµÑ€Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð° ÑƒÐ±Ñ‹Ñ‚ÐºÐ¾Ð²',
    #   'Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² Ð¾Ð± Ð¾Ñ‚ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð¼, Ð½Ð¾Ð²Ð°Ñ†Ð¸Ð¸ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¸Ð¸ Ð´Ð¾Ð»Ð³Ð°, Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð² Ð¾Ð± ÑƒÑÑ‚ÑƒÐ¿ÐºÐµ Ð¿Ñ€Ð°Ð²Ð° Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ðµ Ð´Ð¾Ð»Ð³Ð°',
    #   'Ð½ÐµÑ†ÐµÐ»ÐµÐ²Ð¾Ðµ Ñ€Ð°ÑÑ…Ð¾Ð´Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð¼ Ð´ÐµÐ½ÐµÐ¶Ð½Ñ‹Ñ… ÑÑ€ÐµÐ´ÑÑ‚Ð²'
    # ],

    ContractSubject.Loans: [
      'Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¹Ð¼Ð¾Ð², ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð¾Ð² (Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð²ÐµÐºÑÐµÐ»ÑŒÐ½Ñ‹Ñ…)',
      'Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹ Ð¸ Ð¿Ð¾Ñ€ÑƒÑ‡Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð² Ð¿Ð¾ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°Ð¼',
      'Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¹Ð¼Ð° Ð¸Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð·Ð°Ð¸Ð¼ÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ, ÐºÑ€ÐµÐ´Ð¸Ñ‚Ð°, Ñ„Ð¸Ð½Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ, Ð²Ñ‹Ð¿Ð»Ð°Ñ‚Ñ‹ Ð¸Ð»Ð¸ Ð¾Ñ‚ÑÑ€Ð¾Ñ‡ÐºÐ¸ Ð¿Ð¾ Ð·Ð°Ð¹Ð¼Ñƒ, ÐºÑ€ÐµÐ´Ð¸Ñ‚Ñƒ, Ñ„Ð¸Ð½Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ð¸Ð»Ð¸ Ð·Ð°Ð´Ð¾Ð»Ð¶ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸',
      'Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²',
      'Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð°Ð½ÐºÐ¾Ð²ÑÐºÐ¸Ñ… Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹'
      # 'Ð¾ Ð²Ñ‹Ð´Ð°Ñ‡Ðµ Ð¸Ð»Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ ÐžÐ±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð¼ Ð²ÐµÐºÑÐµÐ»ÐµÐ¹, Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²Ðµ Ð¿Ð¾ Ð½Ð¸Ð¼ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ð½Ð°Ð´Ð¿Ð¸ÑÐµÐ¹, Ð°Ð²Ð°Ð»ÐµÐ¹, Ð¿Ð»Ð°Ñ‚ÐµÐ¶ÐµÐ¹',
    ],

    ContractSubject.Renting: [
      'Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð² Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð¸Ð»Ð¸ ÑÑƒÐ±Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾Ð³Ð¾ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°',
      'Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÑÐ´ÐµÐ»Ð¾Ðº, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸ÐµÐ¼ Ð² Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾cÑ‚Ð¸'
    ],

    ContractSubject.RentingOut: [
      'Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð² Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð¸Ð»Ð¸ ÑÑƒÐ±Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾Ð³Ð¾ Ð¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°',
      'Ð¾ ÑÐ¾Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¸ ÑÐ´ÐµÐ»Ð¾Ðº, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡ÐµÐ¹ Ð² Ð°Ñ€ÐµÐ½Ð´Ñƒ Ð½ÐµÐ´Ð²Ð¸Ð¶Ð¸Ð¼Ð¾cÑ‚Ð¸'

    ]

  }

  def __init__(self, embedder: AbstractEmbedder = None, sentence_embedder: AbstractEmbedder = None):
    ParsingContext.__init__(self, embedder, sentence_embedder)

    self.patterns_dict: DataFrame = _make_org_level_patterns()

    self._patterns_named_embeddings: DataFrame or None = None
    self._subj_patterns_embeddings = None

  def get_patterns_named_embeddings(self):
    if self._patterns_named_embeddings is None:
      __patterns_embeddings = self.get_sentence_embedder().embedd_strings(self.patterns_dict.values[0])
      self._patterns_named_embeddings = pd.DataFrame(__patterns_embeddings.T, columns=self.patterns_dict.columns)

    return self._patterns_named_embeddings

  def get_subj_patterns_embeddings(self):

    if self._subj_patterns_embeddings is None:
      self._subj_patterns_embeddings = embedd_charter_subject_patterns(CharterParser.strs_subjects_patterns,
                                                                       self.get_embedder())

    return self._subj_patterns_embeddings

  def _embedd(self, charter: CharterDocument):

    ### âš™ï¸ðŸ”® SENTENCES embedding

    charter.sentences_embeddings = embedd_sentences(charter.sentence_map, self.get_sentence_embedder())
    charter.distances_per_sentence_pattern_dict = calc_distances_per_pattern(charter.sentences_embeddings,
                                                                             self.get_patterns_named_embeddings())

  def find_org_date_number(self, doc: CharterDocument, ctx: AuditContext) -> LegalDocument:
    """
    phase 1, before embedding
    searching for attributes required for filtering
    :param charter:
    :return:
    """
    # charter.sentence_map = tokenize_doc_into_sentences_map(charter, HyperParameters.charter_sentence_max_len)

    # doc.org_tags = find_charter_org(doc)
    doc.attributes_tree.org = find_charter_org_obj(doc)
    doc.attributes_tree.date = find_document_date(doc)

    return doc

  def find_attributes(self, _charter: CharterDocument, ctx: AuditContext) -> CharterDocument:
    # reset for preventing tags doubling
    _charter.reset_attributes()

    self.find_org_date_number(_charter, ctx)

    if _charter.sentences_embeddings is None:
      # lazy embedding
      self._embedd(_charter)

    # --------------
    # (('Pattern name', 16), 0.8978644013404846),
    patterns_by_headers = map_headlines_to_patterns(_charter,
                                                    self.get_patterns_named_embeddings(), self.get_sentence_embedder())

    _parent_org_level_tag_keys = []
    for p_mapping in patterns_by_headers:
      # for each 'competence' article
      _pattern_name = p_mapping[0][0]
      _paragraph_id = p_mapping[0][1]

      paragraph_body: SemanticTag = _charter.paragraphs[_paragraph_id].body
      confidence = p_mapping[1]
      _org_level_name = _pattern_name.split(PATTERN_DELIMITER)[-1]
      org_level: OrgStructuralLevel = OrgStructuralLevel[_org_level_name]
      subdoc = _charter.subdoc_slice(paragraph_body.as_slice())
      # --
      structurallevel = CharterStructuralLevel()
      structurallevel.value = org_level
      structurallevel.set_confidence(confidence)
      structurallevel.set_span(paragraph_body.span)
      _charter.attributes_tree.structural_levels.append(structurallevel)

      self.find_attributes_in_sections(subdoc, structurallevel)

    return _charter

  def find_attributes_in_sections(self, subdoc: LegalDocumentExt, structural_level: CharterStructuralLevel):

    # finding Subjects
    _subject_attentions_map = get_charter_subj_attentions(subdoc, self.get_subj_patterns_embeddings())  # dictionary
    subject_spans: Spans = collect_subjects_spans2(subdoc, _subject_attentions_map)

    # finding Values(amounts)
    values: [ContractValue] = find_value_sign_currency_attention(subdoc, None, absolute_spans=False)
    self._rename_margin_values_tags(values)
    valued_sentence_spans: Spans = collect_sentences_having_constraint_values(subdoc, values, merge_spans=True)

    _united_spans: Spans = []
    for _s in valued_sentence_spans:
      _united_spans.append(_s)
    for _s in subject_spans:
      _united_spans.append(_s)

    _united_spans = merge_colliding_spans(_united_spans, eps=-1)  # TODO: check this

    self.attribute_spans_to_subjects(_united_spans,
                                     subdoc,
                                     structural_level  # OrgStructuralLevel.BoardOfDirectors
                                     )

    # offsetting tags to absolute values
    for value in values: value += subdoc.start
    for competence_tag in structural_level.competences: competence_tag += subdoc.start

    # nesting values (assigning parents)
    for competence in structural_level.competences:  # contract subjects

      for value in values:
        v_group = value.parent
        if competence.contains(v_group.span):
          # v_group.set_parent_tag(competence_tag)
          competence.constraints.append(value.as_ContractPrice())

  def _rename_margin_values_tags(self, values):
    warnings.warn("deprecated", DeprecationWarning)
    # TODO: remove this
    for value in values:
      if value.sign.value < 0:
        sfx = '-max'
      elif value.sign.value > 0:
        sfx = '-min'
      else:
        sfx = ''

      value.parent.kind = f"constraint{sfx}"

    known_keys = []
    k = 0  # constraints numbering
    for value in values:
      k += 1
      if value.parent.get_key() in known_keys:
        value.parent.kind = f"{value.parent.kind}{TAG_KEY_DELIMITER}{k}"

      known_keys.append(value.parent.get_key())

  def attribute_spans_to_subjects(self,
                                  unique_sentence_spans: Spans,
                                  subdoc: LegalDocumentExt,
                                  parent_org_level_tag: CharterStructuralLevel):

    subject_attentions_map: dict = get_charter_subj_attentions(subdoc, self.get_subj_patterns_embeddings())
    all_subjects = list(subject_attentions_map.keys())
    parent_org_level_tag.competences = []
    # attribute sentences to subject
    for contract_value_sentence_span in unique_sentence_spans:

      max_confidence = 0
      best_subject = None

      for subj in all_subjects:
        av: FixedVector = subject_attentions_map[subj]

        confidence_region: FixedVector = av[span_to_slice(contract_value_sentence_span)]
        confidence = estimate_confidence_by_mean_top_non_zeros(confidence_region)

        if confidence > max_confidence:
          max_confidence = confidence
          best_subject = subj
      # end for

      if best_subject is not None:
        competence = Competence()
        competence.value = best_subject
        competence.set_span(contract_value_sentence_span)
        competence.set_confidence(max_confidence)

        parent_org_level_tag.competences.append(competence)

        all_subjects.remove(best_subject)  # taken: avoid duplicates


def collect_sentences_having_constraint_values(subdoc: LegalDocumentExt, contract_values: [ContractValue],
                                               merge_spans=True) -> Spans:
  # collect sentences having constraint values
  unique_sentence_spans: Spans = []
  for contract_value in contract_values:
    contract_value_sentence_span = subdoc.sentence_at_index(contract_value.parent.span[0], return_delimiters=False)
    if contract_value_sentence_span not in unique_sentence_spans:
      unique_sentence_spans.append(contract_value_sentence_span)
    contract_value_sentence_span = subdoc.sentence_at_index(contract_value.parent.span[1], return_delimiters=False)
    if contract_value_sentence_span not in unique_sentence_spans:
      unique_sentence_spans.append(contract_value_sentence_span)
  # --
  # TODO: do not join here, join by subject
  if merge_spans:
    unique_sentence_spans = merge_colliding_spans(unique_sentence_spans, eps=1)
  return unique_sentence_spans


def embedd_charter_subject_patterns(patterns_dict, embedder: AbstractEmbedder):
  emb_subj_patterns = {}
  for subj in patterns_dict.keys():
    strings = patterns_dict[subj]
    prefix = PATTERN_DELIMITER.join(['subject', subj.name])

    emb_subj_patterns[subj] = {
      'patterns': build_sentence_patterns(strings, prefix, subj),
      'embedding': embedder.embedd_strings(strings)
    }

  return emb_subj_patterns


def get_charter_subj_attentions(subdoc: LegalDocumentExt, emb_subj_patterns) -> dict:
  # TODO: use pandas
  _distances_per_subj = {}

  for subj in emb_subj_patterns.keys():
    patterns_distances = calc_distances_per_pattern_dict(subdoc.sentences_embeddings,
                                                         emb_subj_patterns[subj]['patterns'],
                                                         emb_subj_patterns[subj]['embedding'])

    prefix = PATTERN_DELIMITER.join(['subject', subj.name])

    subj_av = relu(max_exclusive_pattern_by_prefix(patterns_distances, prefix), 0.6)  # TODO: use hyper parameter
    subj_av_words = remap_attention_vector(subj_av, subdoc.sentence_map, subdoc.tokens_map)

    _distances_per_subj[subj] = subj_av_words

  return _distances_per_subj


def collect_subjects_spans2(subdoc, subject_attentions_map, min_len=20) -> Spans:
  spans = []
  for subj in subject_attentions_map.keys():

    subject_attention = subject_attentions_map[subj]
    paragraph_span, confidence, _ = _find_most_relevant_paragraph(subdoc,
                                                                  subject_attention,
                                                                  min_len=min_len,
                                                                  return_delimiters=False)
    if confidence > HyperParameters.charter_subject_attention_confidence:
      if paragraph_span not in spans:
        spans.append(paragraph_span)

  unique_sentence_spans = merge_colliding_spans(spans, eps=-1)

  return unique_sentence_spans


def find_charter_org_obj(doc: LegalDocument) -> ContractAgent or None:
  _subdoc = doc[0:HyperParameters.protocol_caption_max_size_words]

  orgs: [ContractAgent] = find_org_names_raw(_subdoc, max_names=1)
  if len(orgs) == 0:
    return None

  return orgs[0]


def find_charter_org(charter: LegalDocument) -> [SemanticTag]:
  """
  TODO: see also find_protocol_org
  :param charter:
  :return:
  """
  ret = []
  x: [SemanticTag] = find_org_names(charter[0:HyperParameters.protocol_caption_max_size_words], max_names=1)
  nm = SemanticTag.find_by_kind(x, 'org-1-name')
  if nm is not None:
    ret.append(nm)
  else:
    charter.warn(ParserWarnings.org_name_not_found)

  tp = SemanticTag.find_by_kind(x, 'org-1-type')
  if tp is not None:
    ret.append(tp)
  else:
    charter.warn(ParserWarnings.org_type_not_found)

  return ret


def map_headlines_to_patterns(doc: LegalDocument,
                              patterns_named_embeddings: DataFrame,
                              elmo_embedder_default: AbstractEmbedder):
  warnings.warn("consider using map_headers, it returns probalility distribution", DeprecationWarning)
  headers: [str] = doc.headers_as_sentences()

  if not headers:
    return []

  headers_embedding = elmo_embedder_default.embedd_strings(headers)

  header_to_pattern_distances = calc_distances_per_pattern(headers_embedding, patterns_named_embeddings)
  return attribute_patternmatch_to_index(header_to_pattern_distances)
