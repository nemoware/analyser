#!/usr/bin/python
# -*- coding: utf-8 -*-
# coding=utf-8


from legal_docs import LegalDocument, HeadlineMeta
from legal_docs import extract_all_contraints_from_sentence
from legal_docs import rectifyed_sum_by_pattern_prefix, tokenize_text
from ml_tools import *
from parsing import ParsingContext, ParsingConfig
from patterns import AbstractPatternFactoryLowCase
from renderer import AbstractRenderer
from sections_finder import SectionsFinder, FocusingSectionsFinder
from transaction_values import ValueConstraint

subject_types = {
  'charity': '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'.upper(),
  'comm': '–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è —Å–¥–µ–ª–∫–∞'.upper(),
  'comm_estate': '–Ω–µ–¥–≤–∏–∂–µ–º–æ—Å—Ç—å'.upper(),
  'comm_service': '–æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥'.upper()
}

subject_types_dict = {**subject_types, **{'unknown': '–ø—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–æ–≤–æ—Ä–∞ –Ω–µ —è—Å–µ–Ω'}}

default_contract_parsing_config: ParsingConfig = ParsingConfig()
default_contract_parsing_config.headline_attention_threshold = 0.9


class ContractAnlysingContext(ParsingContext):
  def __init__(self, embedder, renderer: AbstractRenderer):
    ParsingContext.__init__(self, embedder, renderer)

    self.price_factory = ContractValuePatternFactory(embedder)
    self.hadlines_factory = ContractHeadlinesPatternFactory(embedder)
    self.subj_factory = ContractSubjPatternFactory(embedder)

    self.contract = None
    self.contract_values = None

    self.config = default_contract_parsing_config

    # self.sections_finder: SectionsFinder = DefaultSectionsFinder(self)
    self.sections_finder: SectionsFinder = FocusingSectionsFinder(self)

  def _reset_context(self):
    super(ContractAnlysingContext, self)._reset_context()

    if self.contract is not None:
      del self.contract
      self.contract = None

    if self.contract_values is not None:
      del self.contract_values
      self.contract_values = None

  def analyze_contract(self, contract_text):
    self._reset_context()
    """
    MAIN METHOD
    
    :param contract_text: 
    :return: 
    """
    doc = ContractDocument2(contract_text)
    doc.parse()
    self.contract = doc

    self._logstep("parsing document üëû and detecting document high-level structure")

    self.contract.embedd(self.hadlines_factory)
    self.sections_finder.find_sections(doc, self.hadlines_factory, self.hadlines_factory.headlines,
                                       headline_patterns_prefix='headline.')

    # -------------------------------values
    values = self.fetch_value_from_contract(doc)
    # -------------------------------subj
    doc.subject = self.recognize_subject(doc)
    self._logstep("fetching transaction values")
    # -------------------------------values

    self.renderer.render_values(values)
    self.contract_values = values
    doc.contract_values = values

    self.log_warnings()

    return doc, values

  def select_most_confident_if_almost_equal(self, a: ProbableValue, alternative: ProbableValue, m_convert,
                                            equality_range=0.0):

    if abs(m_convert(a.value).value - m_convert(alternative.value).value) < equality_range:
      if a.confidence > alternative.confidence:
        return a
      else:
        return alternative
    return a

  def find_contract_best_value(self, m_convert):
    best_value: ProbableValue = max(self.contract_values,
                                    key=lambda item: m_convert(item.value).value)

    most_confident_value = max(self.contract_values, key=lambda item: item.confidence)
    best_value = self.select_most_confident_if_almost_equal(best_value, most_confident_value, m_convert,
                                                            equality_range=20)

    return best_value

  def make_subj_attention_vectors(self, subdoc, subj_types_prefixes):
    r = {}
    for subj_types_prefix in subj_types_prefixes:
      attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, subj_types_prefix)
      attention_vector_l = relu(attention_vector, 0.6)

      r[subj_types_prefix + 'attention_vector'] = attention_vector
      r[subj_types_prefix + 'attention_vector_l'] = attention_vector_l

    return r

  def recognize_subject(self, doc):

    if 'subj' in doc.sections:
      subj_section = doc.sections['subj']

      subj_ = subj_section.body

      # ===================
      # subj_.embedd(self.subj_factory)
      subj_.calculate_distances_per_pattern(self.subj_factory)
      subj_.reset_embeddings()
      prefixes = [f't_{st}_' for st in subject_types]
      r = self.make_subj_attention_vectors(subj_, prefixes)

      interresting_vectors = [r[f't_{st}_attention_vector_l'] for st in subject_types]

      interresting_vectors_means = [np.nanmean(x) for x in interresting_vectors]
      interresting_vectors_maxes = [np.nanmax(x) for x in interresting_vectors]

      winner_id = int(np.argmax(interresting_vectors_means))

      winner_t = prefixes[winner_id][2:-1]

      confidence = interresting_vectors_maxes[winner_id]
      if confidence < 0.3:
        winner_t = 'unknown'

      return winner_t, confidence


    else:
      print('‚ö†Ô∏è —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–µ–¥–º–µ—Ç–µ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω')
      return ('unknown', 0)

  def fetch_value_from_contract(self, contract: LegalDocument) -> List[ProbableValue]:

    def filter_nans(vcs: List[ProbableValue]) -> List[ProbableValue]:
      r: List[ProbableValue] = []
      for vc in vcs:
        if vc.value is not None and not np.isnan(vc.value.value):
          r.append(vc)
      return r

    renderer = self.renderer

    price_factory = self.price_factory

    # if self.verbosity_level > 1:
    #   print('-' * 100)
    #   for eh in embedded_headlines:
    #     print(eh.untokenize_cc())

    # if self.verbosity_level > 1:
    #   print('-' * 100)
    #   for bi in hl_meta_by_index:
    #     hl = hl_meta_by_index[bi]
    #     t: LegalDocument = hl.subdoc
    #     print(bi)
    #     print('#{} \t {} \t {:.4f} \t {}'.format(hl.index, hl.type + ('.' * (14 - len(hl.type))),
    #                                              hl.confidence,
    #                                              t.untokenize_cc()
    #                                              ))
    #     renderer.render_color_text(t.tokens_cc, hl.attention_v, _range=[0, 2])

    sections = contract.sections

    result: List[ValueConstraint] = []

    if 'price.' in sections:
      value_section_info: HeadlineMeta = sections['price.']
      value_section = value_section_info.body
      section_name = value_section_info.subdoc.untokenize_cc()
      result = filter_nans(_try_to_fetch_value_from_section(value_section, price_factory))
      if len(result) == 0:
        self.warning(f'–í —Ä–∞–∑–¥–µ–ª–µ "{ section_name }" —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!')

      if self.verbosity_level > 1:
        renderer.render_value_section_details(value_section_info)
        self._logstep(f'searching for transaction values in section  "{ section_name }"')
        # ------------
        value_section.reset_embeddings()  # careful with this. Hope, we will not be required to search here
    else:
      self.warning('–†–∞–∑–¥–µ–ª –ø—Ä–æ —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω!')

    if len(result) == 0:
      if 'subj' in sections:

        # fallback
        value_section_info = sections['subj']
        value_section = value_section_info.body
        section_name = value_section_info.subdoc.untokenize_cc()
        print(f'- –ò—â–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ä–∞–∑–¥–µ–ª–µ { section_name }')
        result: List[ProbableValue] = filter_nans(_try_to_fetch_value_from_section(value_section, price_factory))

        # decrease confidence:
        for _r in result:
          _r.confidence *= 0.7

        if self.verbosity_level > 0:
          print('alt price section DOC', '-' * 20)
          renderer.render_value_section_details(value_section_info)
          self._logstep(f'searching for transaction values in section  "{ section_name }"')

        if len(result) == 0:
          self.warning(f'–í —Ä–∞–∑–¥–µ–ª–µ "{ section_name }" —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!')

    if len(result) == 0:
      if 'pricecond' in sections:

        # fallback
        value_section_info = sections['pricecond']
        value_section = value_section_info.body
        section_name = value_section_info.subdoc.untokenize_cc()
        print(f'-WARNING: –ò—â–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ä–∞–∑–¥–µ–ª–µ { section_name }!')
        result: List[ProbableValue] = filter_nans(_try_to_fetch_value_from_section(value_section, price_factory))
        if self.verbosity_level > 0:
          print('alt price section DOC', '-' * 20)
          renderer.render_value_section_details(value_section_info)
          self._logstep(f'searching for transaction values in section  "{ section_name }"')
        # ------------
        for _r in result:
          _r.confidence *= 0.7
        value_section.reset_embeddings()  # careful with this. Hope, we will not be required to search here
        if len(result) == 0:
          self.warning(f'–í —Ä–∞–∑–¥–µ–ª–µ "{ section_name }" —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!')

    if len(result) == 0:
      self.warning('–ò—â–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ!')

      #     trying to find sum in the entire doc
      value_section = contract
      result: List[ProbableValue] = filter_nans(_try_to_fetch_value_from_section(value_section, price_factory))
      if self.verbosity_level > 1:
        print('ENTIRE DOC', '--' * 70)
        self._logstep(f'searching for transaction values in the entire document')
      # ------------
      # decrease confidence:
      for _r in result:
        _r.confidence *= 0.6
      value_section.reset_embeddings()  # careful with this. Hope, we will not be required to search here

    return result


class ContractHeadlinesPatternFactory(AbstractPatternFactoryLowCase):

  def __init__(self, embedder):
    # self.headlines = ['subj', 'contract', 'def', 'price.', 'pricecond', 'terms', 'dates', 'break', 'rights', 'obl',
    #                   'resp', 'forcemajor', 'confidence', 'special', 'appl', 'addresses', 'conficts']

    self.headlines = ['subj', 'contract', 'price.', 'pricecond', 'dates',
                      'resp', 'forcemajor', 'confidence', 'appl', 'addresses', 'conficts']

    AbstractPatternFactoryLowCase.__init__(self, embedder)

    self._build_head_patterns()
    self.embedd()

  def _build_head_patterns(self):
    def cp(name, tuples):
      return self.create_pattern(name, tuples)

    PRFX = ''

    cp('headline.contract', (PRFX, '–î–û–ì–û–í–û–†',
                             '\n –≥–æ—Ä–æ–¥, –º–µ—Å—è—Ü, –≥–æ–¥ \n –æ–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é, –≤ –ª–∏—Ü–µ, –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏, –∏–º–µ–Ω—É–µ–º–æ–µ –¥–∞–ª–µ–µ, –∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –æ –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º'))
    cp('headline.def', (PRFX, '–¢–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è', '—Ç–æ–ª–∫–æ–≤–∞–Ω–∏—è'))

    cp('headline.subj.1', ('–¥–æ–≥–æ–≤–æ—Ä–∞ –∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –î–æ–≥–æ–≤–æ—Ä –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º:', '–ü—Ä–µ–¥–º–µ—Ç ',
                           '–¥–æ–≥–æ–≤–æ—Ä–∞:\n –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è, –∑–∞–∫–∞–∑—á–∏–∫ –ø–æ—Ä—É—á–∞–µ—Ç'))
    cp('headline.subj.2', (PRFX, '–ü–†–ï–î–ú–ï–¢', '–î–û–ì–û–í–û–†–ê'))
    cp('headline.subj.3', ('–∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –æ –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º', '–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è', ''))

    cp('headline.price.1', (PRFX, '—Ü–µ–Ω–∞', '–¥–æ–≥–æ–≤–æ—Ä–∞'))
    cp('headline.price.2', (PRFX, '–°–¢–û–ò–ú–û–°–¢–¨', '–†–ê–ë–û–¢'))
    cp('headline.price.3', (PRFX, ' –†–∞—Å—á–µ—Ç—ã', '–ø–æ –¥–æ–≥–æ–≤–æ—Ä—É'))
    cp('headline.price.4', (PRFX, '–û–ø–ª–∞—Ç–∞', '—É—Å–ª—É–≥'))
    cp('headline.price.5',
       ('–ø–æ—Ä—è–¥–æ–∫ –∏ —Å—Ä–æ–∫–∏', '–æ–ø–ª–∞—Ç—ã', '—Å–æ–≥–ª–∞—Å–æ–≤—ã–≤–∞—é—Ç—Å—è –°—Ç–æ—Ä–æ–Ω–∞–º–∏ –≤ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–æ–≥–ª–∞—à–µ–Ω–∏—è—Ö –∫ –Ω–∞—Å—Ç–æ—è—â–µ–º—É'))

    cp('headline.pricecond.1', ('–£–°–õ–û–í–ò–Ø ', '–ü–õ–ê–¢–ï–ñ–ï–ô', ''))
    cp('headline.pricecond.3', ('–£—Å–ª–æ–≤–∏—è –∏ –ø–æ—Ä—è–¥–æ–∫', '—Ä–∞—Å—á–µ—Ç–æ–≤.', ''))
    cp('headline.pricecond.4', (PRFX, '–°–¢–û–ò–ú–û–°–¢–¨', '–£–°–õ–£–ì, –ü–û–†–Ø–î–û–ö –ò–• –ü–†–ò–ï–ú–ö–ò –ò –†–ê–°–ß–ï–¢–û–í'))
    cp('headline.pricecond.5', (' –ê–†–ï–ù–î–ù–ê–Ø', '–ü–õ–ê–¢–ê', '–ü–û–†–Ø–î–û–ö –í–ù–ï–°–ï–ù–ò–Ø –ê–†–ï–ù–î–ù–û–ô –ü–õ–ê–¢–´'))

    cp('headline.dates.1', (PRFX, '–°–†–û–ö–ò.', '–í–´–ü–û–õ–ù–ï–ù–ò–Ø –†–ê–ë–û–¢.–ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç.'))

    cp('headline.dates.2', (PRFX, '–°–†–û–ö',
                          '–î–ï–ô–°–¢–í–ò–Ø. \n –Ω–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω–∞–º–∏, –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∫ –¥–æ–≥–æ–≤–æ—Ä—É –æ—Ñ–æ—Ä–º–ª—è—é—Ç—Å—è –ø–∏—Å—å–º–µ–Ω–Ω—ã–º —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ–º —Å—Ç–æ—Ä–æ–Ω, –ø—Ä–æ–¥–ª–µ–Ω–Ω—ã–º –Ω–∞ –∫–∞–∂–¥—ã–π –ø–æ—Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥'))
    cp('headline.break', (PRFX, '–†–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ',
                          '–¥–æ–≥–æ–≤–æ—Ä–∞. \n –¥–æ—Å—Ä–æ—á–Ω–æ–µ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–∞, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º –æ –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏–∏, —Ä–∞—Å—Ç–æ—Ä–≥–∞–µ—Ç—Å—è –≤ —Å–ª—É—á–∞—è—Ö, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º, –≤ –æ–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ–º –ø–æ—Ä—è–¥–∫–µ'))

    cp('headline.rights.1', (PRFX, '–ø—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏', '—Å—Ç–æ—Ä–æ–Ω.\n'))
    cp('headline.obl.1', (PRFX, '–û–ë–Ø–ó–ê–¢–ï–õ–¨–°–¢–í–ê', '—Å—Ç–æ—Ä–æ–Ω.\n'))
    cp('headline.obl.2', (PRFX, '–ì–ê–†–ê–ù–¢–ò–ô–ù–´–ï', '–û–ë–Ø–ó–ê–¢–ï–õ–¨–°–¢–í–ê.'))

    cp('headline.resp', (PRFX, '–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç–æ—Ä–æ–Ω.\n',
                         '–Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –Ω–µ–Ω–∞–¥–ª–µ–∂–∞—â–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–≤–æ–∏—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤, –Ω–µ—Å—É—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º'))

    cp('headline.forcemajor.1', (PRFX, '–ù–ï–ü–†–ï–û–î–û–õ–ò–ú–ê–Ø –°–ò–õ–ê.', '–§–û–†–°-–ú–ê–ñ–û–†–ù–´–ï –û–ë–°–¢–û–Ø–¢–ï–õ–¨–°–¢–í–ê'))
    cp('headline.forcemajor.2', (PRFX, '–û–ë–°–¢–û–Ø–¢–ï–õ–¨–°–¢–í–ê –ù–ï–ü–†–ï–û–î–û–õ–ò–ú–û–ô –°–ò–õ–´', ''))

    cp('headline.confidence', (PRFX, '–ö–û–ù–§–ò–î–ï–ù–¶–ò–ê–õ–¨–ù–û–°–¢–¨ –ò–ù–§–û–†–ú–ê–¶–ò–ò.', ''))

    cp('headline.special.1', (PRFX + '–û–°–û–ë–´–ï, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ', ' –£–°–õ–û–í–ò–Ø.', ''))
    cp('headline.special.2', (PRFX, '–ó–ê–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–´–ï –ü–û–õ–û–ñ–ï–ù–ò–Ø.', ''))

    cp('headline.appl', (PRFX, '–ü–†–ò–õ–û–ñ–ï–ù–ò–Ø', '–ö –î–û–ì–û–í–û–†–£'))
    cp('headline.addresses.1', (PRFX, '–†–ï–ö–í–ò–ó–ò–¢–´ –°–¢–û–†–û–ù', '–Æ–†–ò–î–ò–ß–ï–°–ö–ò–ï –ê–î–†–ï–°–ê'))
    cp('headline.addresses.2', (PRFX, '–Æ–†–ò–î–ò–ß–ï–°–ö–ò–ï –ê–î–†–ï–°–ê', '–†–ï–ö–í–ò–ó–ò–¢–´ –°–¢–û–†–û–ù'))

    cp('headline.conficts', (PRFX, '–°–ø–æ—Ä—ã –∏ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è.', ''))


class ContractValuePatternFactory(AbstractPatternFactoryLowCase):

  def __init__(self, embedder):
    AbstractPatternFactoryLowCase.__init__(self, embedder)

    self._build_sum_patterns()
    self.embedd()

  def _build_sum_patterns(self):
    def cp(name, tuples):
      return self.create_pattern(name, tuples)

    suffix = '(–º–ª–Ω. —Ç—ã—Å. –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π –¥–æ–ª–ª–∞—Ä–æ–≤ –∫–æ–ø–µ–µ–∫ –µ–≤—Ä–æ)'

    cp('_phrase.1', ('–æ–±—â–∞—è', '—Å—É–º–º–∞', '–¥–æ–≥–æ–≤–æ—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç'))

    cp('_sum.work.1', ('–°—Ç–æ–∏–º–æ—Å—Ç—å –†–∞–±–æ—Ç —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç', '0 —Ä—É–±–ª–µ–π', suffix))
    cp('_sum.work.2', ('–†–∞—Å—á–µ—Ç—ã –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É. –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–∫–∞–∑—ã–≤–∞–µ–º—ã—Ö —É—Å–ª—É–≥ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç ', '0', suffix))
    cp('_sum.work.3', ('–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–æ–≤ –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å', '0', suffix))
    cp('_sum.work.4', ('–ø–æ—Å–ª–µ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—á–µ—Ç–∞ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç —Å—É–º–º—É –≤ —Ä–∞–∑–º–µ—Ä–µ', '0', suffix))
    cp('_sum.work.5', ('–û–±—â–∞—è —Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç', '0', suffix))

    cp('sum_neg.phone', ('—Ç–µ–ª–µ—Ñ–æ–Ω', '00-00-00', ''))

    cp('sum_neg.penalty', ('—É–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è', '—à—Ç—Ä–∞—Ñ', '0 —Ä—É–±–ª–µ–π –∞ —Ç–∞–∫–∂–µ –≤–æ–∑–º–µ—â–∞—é—Ç—Å—è –ø–æ–Ω–µ—Å–µ–Ω–Ω—ã–µ —É–±—ã—Ç–∫–∏'))
    cp('sum_neg.3', (
      '–í —Å–ª—É—á–∞–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è  —Å—Ä–æ–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –†–∞–±–æ—Ç –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—é , –ó–∞–∫–∞–∑—á–∏–∫ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ –≤–∑—ã—Å–∫–∞—Ç—å –ø–µ–Ω–∏ –≤ —Ä–∞–∑–º–µ—Ä–µ',
      '0%', '–æ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –≤–æ–≤—Ä–µ–º—è —ç—Ç–∞–ø–∞ –†–∞–±–æ—Ç –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—é –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏'))
    cp('sum_neg.date.1', ('–≤ —Å—Ä–æ–∫ –Ω–µ –ø–æ–∑–¥–Ω–µ–µ, —á–µ–º –∑–∞ 0 –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö', '–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö', ' –¥–Ω–µ–π'))
    cp('sum_neg.vat', ('–≤ —Ç–æ–º —á–∏—Å–ª–µ', '–ù–î–°', '0 ' + suffix))
    cp('sum_neg.date.2', ('–≤ —Ç–µ—á–µ–Ω–∏–µ', '0', '—Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π '))

  def make_contract_value_attention_vectors(self, subdoc):
    sumphrase_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, '_phrase')
    sumphrase_attention_vector = momentum(sumphrase_attention_vector, 0.99)

    value_attention_vector, _c1 = rectifyed_sum_by_pattern_prefix(subdoc.distances_per_pattern_dict, '_sum.work',
                                                                  relu_th=0.4)
    value_attention_vector = cut_above(value_attention_vector, 1)
    value_attention_vector = relu(value_attention_vector, 0.6)
    value_attention_vector = momentum(value_attention_vector, 0.8)

    novalue_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 'sum_neg')

    novalue_attention_vector_local_contrast = relu(novalue_attention_vector, 0.6)
    novalue_attention_vector_local_contrast = momentum(novalue_attention_vector_local_contrast, 0.9)

    value_attention_vector_tuned = (value_attention_vector - novalue_attention_vector * 0.7)

    value_attention_vector_tuned = (value_attention_vector_tuned + sumphrase_attention_vector) / 2
    value_attention_vector_tuned = relu(value_attention_vector_tuned, 0.2)

    return {
      'sumphrase_attention_vector': sumphrase_attention_vector,
      'value_attention_vector': value_attention_vector,
      'novalue_attention_vector': novalue_attention_vector,

      'novalue_attention_vector_local_contrast': novalue_attention_vector_local_contrast,
      'value_attention_vector_tuned': value_attention_vector_tuned,

    }


# ----------------------------------------------------------------------------------------------
def subdoc_between_lines(line_a: int, line_b: int, doc):
  _str = doc.structure.structure
  start = _str[line_a].span[1]
  if line_b is not None:
    end = _str[line_b].span[0]
  else:
    end = len(doc.tokens)

  return doc.subdoc(start, end)


# ----------------------------------------------------------------------------------------------


def _try_to_fetch_value_from_section(value_section: LegalDocument, factory: ContractValuePatternFactory) -> List[
  ProbableValue]:
  # value_section.embedd(factory)
  value_section.calculate_distances_per_pattern(factory)

  # context._logstep(f'embedding for transaction values in section  "{ section_name }"')

  vectors = factory.make_contract_value_attention_vectors(value_section)

  value_section.distances_per_pattern_dict = {**value_section.distances_per_pattern_dict, **vectors}

  values: List[ProbableValue] = extract_all_contraints_from_sentence(value_section,
                                                                     value_section.distances_per_pattern_dict[
                                                                       'value_attention_vector_tuned'])

  return values


# ----------------------------------


class ContractDocument2(LegalDocument):
  def __init__(self, original_text: str):
    LegalDocument.__init__(self, original_text)
    self.subject = ('unknown', 1.0)
    self.contract_values = [ProbableValue]

  def tokenize(self, _txt):
    return tokenize_text(_txt)


##---------------------------------------##---------------------------------------##---------------------------------------


class ContractSubjPatternFactory(AbstractPatternFactoryLowCase):

  def __init__(self, embedder):
    AbstractPatternFactoryLowCase.__init__(self, embedder)
    self._build_subject_patterns()
    self.embedd()

  def _build_subject_patterns(self):
    def cp(name, tuples):
      return self.create_pattern(name, tuples)

    cp('t_charity_1', ('–¥–æ–≥–æ–≤–æ—Ä',
                       '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ',
                       '–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è'))

    cp('t_charity_2', ('–¥–æ–≥–æ–≤–æ—Ä –æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏',
                       '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–π –ø–æ–º–æ—â–∏',
                       '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π'))

    cp('t_charity_3', ('–ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ',
                       '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö',
                       ''))

    cp('t_charity_4', ('', '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å', ''))
    cp('t_charity_5', ('', '–ë–ª–∞–≥–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å', ''))

    cp('t_charity_6', ('–ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ',
                       '–ü–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è',
                       ''))

    cp('t_charity_7', ('',
                       '–ñ–µ—Ä—Ç–≤–æ–≤–∞—Ç–µ–ª—å',
                       '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ –ø–µ—Ä–µ–¥–∞–µ—Ç –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∞ –ë–ª–∞–≥–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç'))

    cp('t_charity_8', ('–ñ–µ—Ä—Ç–≤–æ–≤–∞—Ç–µ–ª—å', '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ', ''))

    cp('t_comm_1',
       ('–ü–†–û–î–ê–í–ï–¶ –æ–±—è–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥–∞—Ç—å –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –ü–û–ö–£–ü–ê–¢–ï–õ–Ø, –∞', '–ü–û–ö–£–ü–ê–¢–ï–õ–¨', '–æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å'))
    cp('t_comm_estate_2', ('–ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å',
                           '–ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É',
                           '–∑–∞ –ø–ª–∞—Ç—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–¥–≤–∏–∂–∏–º–æ–µ –∏–º—É—â–µ—Å—Ç–≤–æ '))

    cp('t_comm_service_3', ('–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è —Å–≤–æ–∏–º–∏ —Å–∏–ª–∞–º–∏',
                            '–≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–∞–±–æ—Ç—ã',
                            '–ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ'))

    cp('t_comm_service_4', ('–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è',
                            '–æ–∫–∞–∑–∞—Ç—å —É—Å–ª—É–≥–∏',
                            ''))

    cp('t_comm_service_5', ('–ó–∞–∫–∞–∑—á–∏–∫ –ø–æ—Ä—É—á–∞–µ—Ç –∏ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç, –∞ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç ', '—É—Å–ª—É–≥–∏', '–≤ –≤–∏–¥–µ'))
    cp('t_comm_service_6', ('–¥–æ–≥–æ–≤–æ—Ä –Ω–∞ –æ–∫–∞–∑–∞–Ω–∏–µ', '–ø–ª–∞—Ç–Ω—ã—Ö', '—É—Å–ª—É–≥'))
    cp('t_comm_service_7', ('–¥–æ–≥–æ–≤–æ—Ä', '–≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ', '–æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥'))
