#!/usr/bin/python
# -*- coding: utf-8 -*-
# coding=utf-8


import os
import pickle
import unittest

from headers_detector import doc_features, load_model
from legal_docs import LegalDocument


def print_predictions(contract, predictions, body_lines_ranges):
  headlines_cnt = 0
  for i in range(len(predictions)):
    if predictions[i] > 0.1:
      headlines_cnt += 1
      # //print(f'{predictions[i]} \t {i}\tüéñ{contract.tokens_map.text_range(body_lines_ranges[i])}‚ùó')
  return headlines_cnt


class TestHeaderDetector(unittest.TestCase):

  @unittest.skip("headers detector should be retrained")
  def test_doc_features(self):
    with open(os.path.join(os.path.dirname(__file__), '2. –î–æ–≥–æ–≤–æ—Ä –ø–æ –±–ª–∞–≥-—Ç–∏ –†–∞–¥—É–≥–∞.docx.pickle'), 'rb') as handle:
      contract: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(contract.tokens_map)
    self.assertEqual(27, len(features))
    print(features[0])
    pass

  def test_doc_features_predict(self):
    with open(os.path.join(os.path.dirname(__file__), '2. –î–æ–≥–æ–≤–æ—Ä –ø–æ –±–ª–∞–≥-—Ç–∏ –†–∞–¥—É–≥–∞.docx.pickle'), 'rb') as handle:
      doc: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(doc.tokens_map)

    model = load_model()
    predictions = model.predict(features)

    headlines_cnt = print_predictions(doc, predictions, body_lines_ranges)
    self.assertLess(headlines_cnt, 12)
    self.assertGreater(headlines_cnt, 6)

  def test_doc_features_predict_protocol(self):
    with open(os.path.join(os.path.dirname(__file__), '–ü—Ä–æ—Ç–æ–∫–æ–ª_–°–î_ 3.docx.pickle'), 'rb') as handle:
      contract: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(contract.tokens_map)

    model = load_model()
    predictions = model.predict(features)

    headlines_cnt = print_predictions(contract, predictions, body_lines_ranges)

    self.assertLess(headlines_cnt, 28)
    self.assertGreater( headlines_cnt, 10)


  def test_doc_features_predict_2(self):
    with open(os.path.join(os.path.dirname(__file__), '–î–æ–≥–æ–≤–æ—Ä 8.docx.pickle'), 'rb') as handle:
      contract: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(contract.tokens_map)

    model = load_model()
    predictions = model.predict(features)

    headlines_cnt = print_predictions(contract, predictions, body_lines_ranges)
    self.assertLess(headlines_cnt, 12)
    self.assertGreater(headlines_cnt, 8)

  @unittest.skip("headers detector should be retrained")
  def test_doc_features_predict_3(self):
    with open(os.path.join(os.path.dirname(__file__), '–î–æ–≥–æ–≤–æ—Ä _2_.docx.pickle'), 'rb') as handle:
      contract: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(contract.tokens_map)

    model = load_model()
    predictions = model.predict(features)

    headlines_cnt = print_predictions(contract, predictions, body_lines_ranges)
    self.assertLess(headlines_cnt, 39)
    self.assertGreater(headlines_cnt, 20)

  def test_doc_features_predict_4(self):
    with open(os.path.join(os.path.dirname(__file__), '–î–æ–≥–æ–≤–æ—Ä 2.docx.pickle'), 'rb') as handle:
      contract: LegalDocument = pickle.load(handle)

    features, body_lines_ranges = doc_features(contract.tokens_map)

    model = load_model()
    predictions = model.predict(features)

    headlines_cnt = print_predictions(contract, predictions, body_lines_ranges)

    self.assertLess(headlines_cnt, 12)
    self.assertGreater(headlines_cnt, 6)


unittest.main(argv=['-e utf-8'], verbosity=3, exit=False)
