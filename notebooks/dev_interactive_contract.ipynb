{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dev: interactive contract.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JbsxFAqC6pjQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbsxFAqC6pjQ",
        "colab_type": "text"
      },
      "source": [
        "## Import code from gitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCAExPc0iE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_git_branch = 'charters-subjects-2'\n",
        "\n",
        "#Document parser, refer https://github.com/nemoware/document-parser/releases\n",
        "lib_version = '1.1.18'\n",
        "document_parser_lib_version=lib_version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr2WafHuH7z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F89NLdN6A8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "!pip install overrides\n",
        "\n",
        "–ù–∏—á—Ç–æ = None\n",
        "\n",
        "\n",
        "def exec(x):\n",
        "  r = subprocess.check_output(x, shell=True)\n",
        "  r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "  print(r)\n",
        "\n",
        "\n",
        "print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "try:\n",
        "  exec('rm -r nlp_tools')\n",
        "except:\n",
        "  pass\n",
        "exec(f'git clone --single-branch --branch {_git_branch} https://github.com/nemoware/analyser.git nlp_tools')\n",
        "\n",
        "print('ü¶ä GIT revision:')\n",
        "exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "print('‚ù§Ô∏èimporting Code from GitHub ... DONE')\n",
        "\n",
        "#----- other deps\n",
        "!pip install pyjarowinkler\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWpU6LtTkt9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----\n",
        "import matplotlib as mpl\n",
        "from analyser.documents import TextMap\n",
        "from analyser.legal_docs import DocumentJson\n",
        "from colab_support.renderer import HtmlRenderer\n",
        "\n",
        " \n",
        "\n",
        "class DemoRenderer(HtmlRenderer):\n",
        "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
        "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range, separator=separator)\n",
        "    display(HTML(html))\n",
        "\n",
        "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
        "    return super()._to_color_text(tokens, weights, mpl, colormap=colormap, _range=_range, separator=separator)\n",
        "\n",
        "   \n",
        "renderer_ = DemoRenderer()\n",
        "\n",
        "def print_json_summary(cd:DocumentJson):\n",
        "  wordsmap = TextMap(cd.normal_text, cd.tokenization_maps['$words'])\n",
        "  print(f'read file {cd.filename}')\n",
        "\n",
        "  for tag in cd.tags:\n",
        "    span = tag.span\n",
        "    _map = cd.tokenization_maps[tag.span_map]\n",
        "    print(tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPLjOzkOATgk",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-embedded test doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtjuPbUAc7dN",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Pre-embedded or Upload?\n",
        "upload_files = True #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKMB4pkuu2wi",
        "colab_type": "text"
      },
      "source": [
        "### Init document-parser lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415zlWl16SLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib_version = document_parser_lib_version\n",
        "import os\n",
        "if not os.path.isfile(f'document-parser-{lib_version}-distribution.zip'):\n",
        "  !wget https://github.com/nemoware/document-parser/releases/download/$lib_version/document-parser-$lib_version-distribution.zip\n",
        "if not os.path.isdir(f'document-parser-{lib_version}'):\n",
        "  !unzip document-parser-$lib_version-distribution.zip\n",
        "\n",
        " \n",
        "os.environ ['documentparser']=f'/content/document-parser-{lib_version}'\n",
        "from integration.word_document_parser import WordDocParser, join_paragraphs\n",
        "wp = WordDocParser()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNmYb03dFcJ9",
        "colab_type": "text"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fbSX2h2MedM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import unittest\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from analyser.contract_parser import ContractAnlysingContext, ContractDocument\n",
        "#from analyser.contract_parser import find_value_sign_currency_attention\n",
        "from analyser.contract_patterns import ContractPatternFactory\n",
        " \n",
        " \n",
        "# from headers_detector import doc_features, load_model, make_headline_attention_vector\n",
        "from analyser.hyperparams import HyperParameters\n",
        "from analyser.contract_parser import ContractAnlysingContext\n",
        "from analyser.parsing import AuditContext\n",
        "\n",
        "from analyser.legal_docs import LegalDocument, ContractValue\n",
        "from analyser.ml_tools import *\n",
        "from analyser.patterns import *\n",
        "from analyser.text_tools import *\n",
        "\n",
        "from tf_support.embedder_elmo import ElmoEmbedder\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCveVZqvNhsr",
        "colab_type": "text"
      },
      "source": [
        "## üíÖ Init Embedder(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3k194xUFy20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo_embedder = ElmoEmbedder()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmjcOzx_5wdZ",
        "colab_type": "text"
      },
      "source": [
        "## Init parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9n6GgQd5vqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = ContractAnlysingContext(elmo_embedder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDRIF48ks3OV",
        "colab_type": "text"
      },
      "source": [
        "# Read doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waeVpcnaLgEJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ‚úÖRead uploaded file\n",
        "\n",
        "filename = '/content/8.\\u0434\\u043E\\u0433\\u043E\\u0432\\u043E\\u0440.doc' #@param {type:\"string\"} \n",
        "trim_doc =  False #@param {type:\"boolean\"} \n",
        " \n",
        "results = wp.read_doc(filename)\n",
        "for doc in results['documents'][:1]:  # XXX\n",
        "  if 'CONTRACT' == doc['documentType']:    \n",
        "    doc = join_paragraphs(doc, 'no_id')\n",
        "\n",
        "# print(doc.original_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q_jn8Yc6pK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in doc.paragraphs:\n",
        "  print ('‚ò¢Ô∏è', p.header.value.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guoqNsrAp0TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ACHTUNG!\n",
        "## TRIM doc, to make debug faster\n",
        "if trim_doc:\n",
        "  doc = doc[0:1500]\n",
        "  doc.paragraphs=None\n",
        "\n",
        "print(doc.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-1MM_4c0Nr",
        "colab_type": "text"
      },
      "source": [
        "# Parse Contract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn3dP0rdnyOE",
        "colab_type": "text"
      },
      "source": [
        "## phase 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtNMZ2vhn0AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "actx = AuditContext()\n",
        "ctx.find_org_date_number(doc, actx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Hi1nL3oOkb",
        "colab_type": "text"
      },
      "source": [
        "### render phase 0 results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjPfDo7oRNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "renderer_.render_color_text(doc.tokens[0:300],  doc.get_tags_attention()[0:300] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86azZSWrqg7H",
        "colab_type": "text"
      },
      "source": [
        "## Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayunp6Laqjhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx.find_attributes(doc, actx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "36P6_6N0qs2t"
      },
      "source": [
        "### render phase 1 results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQg4rwDcqs2v",
        "colab": {}
      },
      "source": [
        "renderer_.render_color_text(doc.tokens,  doc.get_tags_attention()  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6IMiKcq1gL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in doc.get_tags():\n",
        "  print('\\n',t, '-'*80)\n",
        "  print(doc.substr(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miucAiY24-hA",
        "colab_type": "text"
      },
      "source": [
        "### structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZV-zO1k4_4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ctx.sections_finder.find_sections(doc, ctx.pattern_factory, ctx.pattern_factory.headlines,\n",
        "#                                        headline_patterns_prefix='headline.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJc8VWoa4rZs",
        "colab_type": "text"
      },
      "source": [
        "### subject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SbyUT7I4g6q",
        "colab_type": "text"
      },
      "source": [
        "IN doc head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5uwOPBI4ZE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "section = doc[0:1500]\n",
        "denominator = 0.7\n",
        "result = ctx.find_contract_subject_regions(section, denominator)\n",
        "print(result)\n",
        "\n",
        "print( doc.substr(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u0unxKA4jq6",
        "colab_type": "text"
      },
      "source": [
        "in Subject section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxPXwjjn4s66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# subject_section = doc.sections['subj'].body\n",
        "\n",
        "subject_section = doc #or select a section\n",
        "tag = ctx.find_contract_subject_regions(subject_section, 1)\n",
        "print(tag)\n",
        "print(subject_section.substr(tag))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pktjm1OJe9DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWYYUtMF79-u",
        "colab_type": "text"
      },
      "source": [
        "#### subject details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkGzQV5QnxO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subject_headline_attention = subject_section.distances_per_pattern_dict ['subject_headline_attention'] \n",
        "subject_headline_attention_max = max(subject_headline_attention)\n",
        "print('subject_headline_attention_max',subject_headline_attention_max)\n",
        "section=subject_section\n",
        "# all_subjects_headlines_vectors = filter_values_by_key_prefix(subject_section.distances_per_pattern_dict, 'headline.subj')\n",
        "# subject_headline_attention: FixedVector = max_exclusive_pattern(all_subjects_headlines_vectors)\n",
        "# subject_headline_attention = best_above(subject_headline_attention, 0.5)\n",
        "# subject_headline_attention = momentum_t(subject_headline_attention, half_decay=20)\n",
        "\n",
        "\n",
        "# section=subject_section\n",
        "# all_subjects_headlines_vectors = filter_values_by_key_prefix(section.distances_per_pattern_dict, 'headline.subj')\n",
        "\n",
        "# subject_headline_attention: FixedVector = max_exclusive_pattern(all_subjects_headlines_vectors)\n",
        "# subject_headline_attention = best_above(subject_headline_attention, 0.5)\n",
        "# subject_headline_attention = momentum_t(subject_headline_attention, half_decay=80)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_q5SBofmk9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "plt.rcParams[\"figure.figsize\"] = (17,4)\n",
        "fig = plt.figure()  \n",
        "ax = plt.axes(title=f'subject_headline_attention')\n",
        "\n",
        "all_subjects_headlines_vectors = filter_values_by_key_prefix(section.distances_per_pattern_dict, 'headline.subj')\n",
        "subject_headline_attention: FixedVector = max_exclusive_pattern(all_subjects_headlines_vectors)\n",
        "ax.plot(subject_headline_attention)\n",
        "\n",
        "subject_headline_attention = best_above(subject_headline_attention, 0.2)\n",
        "ax.plot(subject_headline_attention)\n",
        "\n",
        "subject_headline_attention = momentum_t(subject_headline_attention, half_decay=120)\n",
        "ax.plot(subject_headline_attention)\n",
        "\n",
        "\n",
        "print(max(subject_headline_attention))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1PaWRdQ_HP4",
        "colab_type": "text"
      },
      "source": [
        "##### ContractSubjects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Uucb_W-hOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from analyser.contract_parser import contract_subjects, _find_most_relevant_paragraph\n",
        "plt.rcParams[\"figure.figsize\"] = (17,4)\n",
        " \n",
        "\n",
        "subject_headline_attention_max = max(subject_headline_attention)\n",
        "for subject_kind in contract_subjects:\n",
        "# subject_kind = ContractSubject.RealEstate\n",
        "  print(\"=\"*20)\n",
        "  print(subject_kind)\n",
        "  subject_attention_vector: FixedVector = ctx.make_subject_attention_vector_3(subject_section, subject_kind, None)\n",
        "  if subject_headline_attention_max > 0.5:\n",
        "    subject_attention_vector *= subject_headline_attention\n",
        "  print(len(subject_attention_vector))\n",
        "  paragraph_span, confidence, paragraph_attention_vector = _find_most_relevant_paragraph(subject_section,\n",
        "                                                                                             subject_attention_vector,\n",
        "                                                                                             min_len=20,\n",
        "                                                                                             return_delimiters=False)\n",
        "  \n",
        "  # confidence_region = subject_attention_vector# subject_attention_vector[paragraph_span[0]:paragraph_span[1]]\n",
        "  # confidence_alt = estimate_confidence_by_non_zeros(subject_attention_vector)\n",
        "  print(confidence,  len(paragraph_attention_vector),'\\n', subject_section.tokens_map.text_range(paragraph_span))\n",
        "\n",
        "  renderer_.render_color_text(subject_section.tokens,  subject_attention_vector, _range=(0,1))\n",
        "\n",
        "  fig = plt.figure()  \n",
        "  ax = plt.axes(title=f'{subject_kind}')\n",
        "  \n",
        "  \n",
        "  # ax.plot(smooth(subject_attention_vector, 30),color=(0,0,1,0.5) )   \n",
        "  \n",
        "  _mark=[max(subject_attention_vector)]*len(subject_attention_vector)\n",
        "  _mark[0:paragraph_span[0]]*=0\n",
        "  _mark[paragraph_span[1]:]*=0\n",
        "  ax.plot(_mark, color=(0,0,0,0.5) )   \n",
        "\n",
        "  _mark=[confidence]*len(subject_attention_vector)\n",
        "  _mark[0:paragraph_span[0]]*=0\n",
        "  _mark[paragraph_span[1]:]*=0\n",
        "  ax.plot(_mark, color=(0,0,0,0.5) )   \n",
        "\n",
        "  \n",
        "  ax.plot( subject_headline_attention , color=(0,1,0,0.5) )   \n",
        "\n",
        "  ax.plot(subject_attention_vector, color=(0,0,0,0.5) )   \n",
        "  ax.plot(paragraph_attention_vector, color=(1,0,0,0.5) )   \n",
        "  \n",
        "  #thresholds\n",
        "  \n",
        "  ax.plot([max(subject_headline_attention)]*len(subject_headline_attention), color=(0,1,0,0.5) )   \n",
        "  ax.plot([max(paragraph_attention_vector)]*len(paragraph_attention_vector), color=(1,0,0,0.5) )   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLooy_xIaf8J",
        "colab_type": "text"
      },
      "source": [
        "### Paragraphs mapping to topics AKA sections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNAYjj9l-e4f",
        "colab_type": "text"
      },
      "source": [
        "print all headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwpCJDg095Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p in doc.paragraphs:\n",
        "  print ('‚ò¢Ô∏è', p.header.value.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAvDeUfxA-zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "factory = ctx.pattern_factory\n",
        "\n",
        "\n",
        "head_subject_patterns_prefix = 'hds_' \n",
        "\n",
        "# XXX: this has been moved to contraact_parser.py\n",
        "contract_headlines_patterns={\n",
        "  '–ö–£–ü–õ–ò-–ü–†–û–î–ê–ñ–ò –ù–ï–î–í–ò–ñ–ò–ú–û–ì–û –ò–ú–£–©–ï–°–¢–í–ê':ContractSubject.RealEstate,\n",
        "  '–∫—É–ø–ª–∏-–ø—Ä–æ–¥–∞–∂–∏':ContractSubject.Deal,  \n",
        "  '–∑–∞–π–º–∞':ContractSubject.Loans,\n",
        "  '–æ–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —É—Å–ª—É–≥':ContractSubject.Consulting,\n",
        "  '–Ω–∞ –æ–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥':ContractSubject.Service,\n",
        "  '–∑–∞–ª–æ–≥–∞':ContractSubject.PledgeEncumbrance,\n",
        "  '–æ –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–π –ø–æ–º–æ—â–∏ ( –ü–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–µ )':ContractSubject.Charity,\n",
        "  '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–µ–∂–∏–ª—ã–º –ø–æ–º–µ—â–µ–Ω–∏–µ–º':ContractSubject.Charity,\n",
        "  '–≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ä—è–¥–∞':ContractSubject.GeneralContract,\n",
        "  '–∞—Ä–µ–Ω–¥—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞':ContractSubject.Renting\n",
        "}\n",
        "\n",
        " \n",
        "\n",
        "# XXX: this has been moved to contraact_parser.py\n",
        "def _build_head_subject_patterns(self):\n",
        "\n",
        "  for txt in contract_headlines_patterns:\n",
        "    cnt = len(self.patterns)    \n",
        "    kind = contract_headlines_patterns[txt]\n",
        "    self.create_pattern(f'{head_subject_patterns_prefix}{kind}.{cnt}',\n",
        "                        ('–î–æ–≥–æ–≤–æ—Ä', txt.lower().strip(), ''))\n",
        "    \n",
        "   \n",
        "\n",
        "_build_head_subject_patterns(factory)\n",
        "factory.embedd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yTE__j3-hpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# XXX: this has been moved to contraact_parser.py\n",
        "def match_headline_to_subject(section: LegalDocument, subject_kind: ContractSubject) -> FixedVector:\n",
        "\n",
        "  pattern_prefix = f'{head_subject_patterns_prefix}{subject_kind}'\n",
        "  _vectors = list(  filter_values_by_key_prefix(section.distances_per_pattern_dict, pattern_prefix) )\n",
        "\n",
        "  if not _vectors:\n",
        "    warnings.warn(f'no patterns for {subject_kind}')\n",
        "    return np.zeros(len(section.tokens_map))\n",
        "    \n",
        "  vectors = [ best_above(v, 0.4) for v in _vectors ]\n",
        "\n",
        "  x = max_exclusive_pattern(vectors)\n",
        "  x = relu(x, 0.6)\n",
        "  \n",
        "  return x\n",
        "\n",
        "# XXX: this has been moved to contraact_parser.py\n",
        "def find_headline_subject_match(doc: LegalDocument, factory: AbstractPatternFactory) -> (ContractSubject, float):\n",
        "  headers = [doc.subdoc_slice(p.header.as_slice()) for p in doc.paragraphs]\n",
        "\n",
        "  max_confidence = 0\n",
        "  best_subj = None\n",
        "  for header_index, header in enumerate(\n",
        "          headers[0:3]):  # take only 3 fist headlines; normally contract type is known by the 1st one.\n",
        "\n",
        "    if header.text and header.text.strip():\n",
        "\n",
        "      vvs = header.calculate_distances_per_pattern(factory, pattern_prefix=head_subject_patterns_prefix, merge=False)\n",
        "      \n",
        "\n",
        "      for subject_kind in contract_headlines_patterns.values():  # like ContractSubject.RealEstate ..\n",
        "        subject_attention_vector: FixedVector = match_headline_to_subject(header, subject_kind)\n",
        "        _confidence = estimate_confidence_by_mean_top_non_zeros(subject_attention_vector)\n",
        "        if _confidence > max_confidence:\n",
        "          max_confidence = _confidence\n",
        "          best_subj = subject_kind\n",
        "\n",
        "        # print (subject_kind, _confidence)\n",
        "\n",
        "  return best_subj, max_confidence\n",
        "\n",
        "\n",
        "best_subj, max_confidence = find_headline_subject_match(doc, factory)\n",
        "print ('-'*20)\n",
        "print (best_subj, max_confidence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjeG2rV6Zknn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find sections\n",
        "sections = ctx.sections_finder.find_sections(doc, \n",
        "                                  ctx.pattern_factory, \n",
        "                                  ctx.pattern_factory.headlines,\n",
        "                                  headline_patterns_prefix='headline.')\n",
        "for s in sections:\n",
        "  print(f'‚ò¢Ô∏è{sections[s].confidence:.4f} \\t {s}\\t\\t  {sections[s].header.strip()} \\t')\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuw8l5ZpOkzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from analyser.ml_tools import *\n",
        "\n",
        "confidence_threshold=0.7\n",
        "sections_filtered = {}\n",
        "for section_type in factory.headlines:\n",
        "  print(section_type, '-'*100)\n",
        "  pattern_prefix = f'headline.{section_type}'\n",
        "\n",
        "  #find best header for each section\n",
        "  headers = [contract.subdoc_slice(p.header.as_slice()) for p in contract.paragraphs]\n",
        "  best_header = headers[0]\n",
        "\n",
        "  _max_confidence = 0\n",
        "  _max_header_i = -1\n",
        "  for header_index in range(len(headers)):\n",
        "    header = headers[header_index]\n",
        "    vvs = header.calculate_distances_per_pattern(factory, pattern_prefix=pattern_prefix, merge=False)\n",
        "    vv = max_exclusive_pattern( list( vvs.values()) ) #bayes-aggregated vectors\n",
        "    _confidence = max(vv)\n",
        "    if _confidence > _max_confidence:\n",
        "      _max_confidence = _confidence\n",
        "      _max_header_i = header_index\n",
        "      best_header = header\n",
        "    # print( vvs.keys())\n",
        "\n",
        "    # renderer_.render_color_text(header.tokens,vv , _range=(0,1))\n",
        "  print (_max_header_i, section_type, _max_confidence, best_header.text)  \n",
        "\n",
        "  if _max_confidence > confidence_threshold:\n",
        "    put_if_better(sections_filtered, _max_header_i, (_max_confidence, section_type, best_header.text), lambda a, b: a[1] < b[1])\n",
        "\n",
        "for k in sections_filtered.values():\n",
        "  print (k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEKtR4vaO6UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# headers = [contract.subdoc_slice(p.header.as_slice()) for p in contract.paragraphs]\n",
        "# for h in headers:\n",
        "#   print (h.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcGDueMOY4Ow",
        "colab_type": "text"
      },
      "source": [
        "## Subject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al6xZ5y6FBU1",
        "colab_type": "text"
      },
      "source": [
        "### make_subject_attention_vector_3\n",
        "–Ω–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è \"–ø—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\" (subj)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi_JcJqasOmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contract.sections['subj'].header"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXkQVpxyE7kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ml_tools import SemanticTag, FixedVector, filter_values_by_key_prefix, rectifyed_sum\n",
        "from structures import ContractSubject\n",
        "\n",
        "section = contract.sections['subj'].body\n",
        " \n",
        "section.calculate_distances_per_pattern(ctx.pattern_factory, merge=True, pattern_prefix='x_ContractSubject')\n",
        "\n",
        "all_subjects_vectors = filter_values_by_key_prefix(section.distances_per_pattern_dict, 'x_ContractSubject')\n",
        "all_subjects_mean: FixedVector = rectifyed_sum(all_subjects_vectors)\n",
        "\n",
        "print(ContractSubject.Deal)\n",
        "subject_kind =  ContractSubject.Deal\n",
        "subject_attention_vector: FixedVector = ctx.make_subject_attention_vector_3(section, subject_kind)\n",
        "\n",
        "renderer_.render_color_text(section.tokens, subject_attention_vector, _range=(0,1))\n",
        "\n",
        "\n",
        "print(ContractSubject.Charity)\n",
        "subject_kind =  ContractSubject.Charity\n",
        "subject_attention_vector: FixedVector = ctx.make_subject_attention_vector_3(section, subject_kind)\n",
        "\n",
        "renderer_.render_color_text(section.tokens, subject_attention_vector, _range=(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYxT9KFNtjim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(section.distances_per_pattern_dict.keys())\n",
        "renderer_.render_color_text(section.tokens, section.distances_per_pattern_dict['$at_x_ContractSubject.Deal'], _range=(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9CRJ19ZAPyG",
        "colab_type": "text"
      },
      "source": [
        "### make_subject_attention_vector_3 (1500)\n",
        "–ø–µ—Ä–≤—ã–µ 1500 —Å–ª–æ–≤, –∫–æ–≥–¥–∞ —Å–µ–∫—Ü–∏—è \"–ø—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\" –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqarSmmYVCp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ml_tools import SemanticTag, FixedVector, filter_values_by_key_prefix, rectifyed_sum\n",
        "from structures import ContractSubject\n",
        "\n",
        "#Finding subject in first 1500 words\n",
        "section = contract.subdoc_slice(slice(0, 1500))\n",
        "\n",
        "section.calculate_distances_per_pattern(ctx.pattern_factory, merge=True, pattern_prefix='x_ContractSubject')\n",
        "\n",
        "all_subjects_vectors = filter_values_by_key_prefix(section.distances_per_pattern_dict, 'x_ContractSubject')\n",
        "all_subjects_mean: FixedVector = rectifyed_sum(all_subjects_vectors)\n",
        "renderer_.render_color_text(section.tokens, all_subjects_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFUvefy3d1lT",
        "colab_type": "text"
      },
      "source": [
        "#### Higlight charity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_5sC3la9QQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from ml_tools import filter_values_by_key_prefix, FixedVector, max_exclusive_pattern, relu\n",
        "# from patterns import AV_PREFIX, AV_SOFT\n",
        "# from structures import ContractSubject\n",
        "\n",
        "\n",
        "# def _subj_attention_names(subj: ContractSubject):\n",
        "#   a = f'x_{subj}'\n",
        "#   b = AV_PREFIX + f'x_{subj}'\n",
        "#   c = AV_SOFT + a\n",
        "#   return a, b, c\n",
        "\n",
        " \n",
        "\n",
        "subject_kind =  ContractSubject.Charity\n",
        "subject_attention_vector: FixedVector = ctx.make_subject_attention_vector_3( section, subject_kind, all_subjects_mean)\n",
        "renderer_.render_color_text(section.tokens, subject_attention_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrLSBkDpuXVL",
        "colab_type": "text"
      },
      "source": [
        "### _find_most_relevant_paragraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpyDo4gQtKy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from legal_docs import LegalDocument\n",
        "from contract_parser import _find_most_relevant_paragraph\n",
        "from ml_tools import  *\n",
        "import numpy as np\n",
        "\n",
        " \n",
        "span, confidence, paragraph_attention_vector = _find_most_relevant_paragraph(section,  subject_attention_vector, min_len=20)\n",
        "\n",
        "renderer_.render_color_text(section.tokens, section.distances_per_pattern_dict['headline.subj.1'], _range=(0,1))\n",
        "\n",
        "print(span, confidence)\n",
        "print (section.tokens_map.text_range(span))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pamY0kReA0y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jkVyEDUeZL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ =section.calculate_distances_per_pattern(ctx.pattern_factory, merge=True, pattern_prefix='headline.subj')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BDivaeW4d7q8"
      },
      "source": [
        "#### Higlight deal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UxH3pb7wd7rA",
        "colab": {}
      },
      "source": [
        "\n",
        "subject_kind =  ContractSubject.Deal\n",
        "subject_attention_vector: FixedVector = ctx.make_subject_attention_vector_3(section, subject_kind,\n",
        "                                                                                   all_subjects_mean)\n",
        "renderer_.render_color_text(section.tokens, subject_attention_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DgCjtPAqKT",
        "colab_type": "text"
      },
      "source": [
        "### Subject sentence (span, region, paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6zU5zyzAshy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#ACHTUNG: this code moved to gitHub codebase, see _find_most_relevant_paragraph\n",
        "\n",
        "attention_vector = subject_attention_vector\n",
        "paragraph_attention_vector = np.zeros_like (attention_vector)\n",
        "top_index=0\n",
        "for i in np.nonzero(attention_vector)[0]:\n",
        "  par = section.tokens_map.sentence_at_index(i)\n",
        "  paragraph_len = par[1]-par[0]\n",
        "  if paragraph_len:\n",
        "    # TODO: Next line is weird\n",
        "    # Calculate density of the matches per paragraph:\n",
        "    density = attention_vector[i] / paragraph_len\n",
        "    paragraph_attention_vector[par[0]: par[1]] += attention_vector[i] + density\n",
        "\n",
        "    if paragraph_attention_vector[par[0]] > paragraph_attention_vector[top_index]:\n",
        "      top_index = par[0]\n",
        "\n",
        "par = section.tokens_map.sentence_at_index(top_index)\n",
        "renderer_.render_color_text(section.tokens_cc, paragraph_attention_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-FgV-8gziyT",
        "colab_type": "text"
      },
      "source": [
        "#### Subject extracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIsL3ksfNw-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contract.tokens_map.text_range(par)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt0JTASszq4N",
        "colab_type": "text"
      },
      "source": [
        "## Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c8y1s4nztYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in contract.get_tags():\n",
        "  print (t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NMBkQQcB8NH",
        "colab_type": "text"
      },
      "source": [
        "#### hilight value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekkvdtEf7DXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_section = contract#.sections['subj'].body\n",
        "\n",
        "value_section.calculate_distances_per_pattern(factory)\n",
        "vectors = factory.make_contract_value_attention_vectors(value_section)\n",
        "value_section.distances_per_pattern_dict = {**value_section.distances_per_pattern_dict, **vectors}\n",
        "\n",
        "renderer_.render_color_text(value_section.tokens, value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY1F40rYayUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from contract_parser import find_value_sign_currency\n",
        "find_value_sign_currency(contract, ctx.pattern_factory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R55p705ybvod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "ctx.find_contract_value_NEW(contract)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWl0i0GWCKLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from typing import List\n",
        "\n",
        "# from contract_patterns import ContractPatternFactory\n",
        "# from legal_docs import LegalDocument, extract_sum_sign_currency\n",
        "# from ml_tools import SemanticTag, estimate_confidence_by_mean_top_non_zeros\n",
        "# from transaction_values import complete_re\n",
        "\n",
        "# transaction_values_re = complete_re\n",
        "\n",
        "\n",
        "# def find_value_sign_currency(value_section_subdoc: LegalDocument, factory: ContractPatternFactory = None) -> List[\n",
        "#   List[SemanticTag]]:\n",
        "#   ''' merge dictionaries of attention vectors '''\n",
        "\n",
        "#   if factory:\n",
        "#     value_section_subdoc.calculate_distances_per_pattern(factory)\n",
        "#     vectors = factory.make_contract_value_attention_vectors(value_section_subdoc)\n",
        "#     value_section_subdoc.distances_per_pattern_dict = {**value_section_subdoc.distances_per_pattern_dict, **vectors}\n",
        "#     attention_vector_tuned = value_section_subdoc.distances_per_pattern_dict['value_attention_vector_tuned']\n",
        "#     # TODO: apply confidence to semantic tags\n",
        "\n",
        "#   spans = [m for m in value_section_subdoc.tokens_map.finditer(transaction_values_re)]\n",
        "#   values_list = [extract_sum_sign_currency(value_section_subdoc, span) for span in spans]\n",
        "\n",
        "#   return values_list\n",
        "\n",
        "\n",
        "# value_section_subdoc = contract\n",
        "# value_section_subdoc.calculate_distances_per_pattern(factory)\n",
        "# vectors = factory.make_contract_value_attention_vectors(value_section_subdoc)\n",
        "# value_section_subdoc.distances_per_pattern_dict = {**value_section_subdoc.distances_per_pattern_dict, **vectors}\n",
        "# attention_vector_tuned = value_section_subdoc.distances_per_pattern_dict['value_attention_vector_tuned']\n",
        "\n",
        "# for value_sign_currency in find_value_sign_currency(value_section_subdoc, factory):\n",
        "#   for t in value_sign_currency:\n",
        "#     t.confidence *= estimate_confidence_by_mean_top_non_zeros( attention_vector_tuned[t.span[0]:t.span[1]])\n",
        "#     print(t.value, t.kind, t.span, t.confidence)\n",
        "\n",
        "#   # print(t)\n",
        "\n",
        "# renderer_.render_color_text(value_section_subdoc.tokens, attention_vector_tuned, _range=(0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-MfwGnrsF1d",
        "colab_type": "text"
      },
      "source": [
        "# TESTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wZNKnW8sHYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from analyser.contract_agents import *\n",
        "\n",
        "def test_find_agent_no_comma(txt_full):\n",
        "  \n",
        "  _doc = LegalDocument(txt_full).parse()\n",
        "  # print(_doc.text)\n",
        "\n",
        "  tags: [SemanticTag] = find_org_names(_doc, decay_confidence=False)\n",
        "  for t in tags:\n",
        "    print(t)\n",
        "\n",
        "test_find_agent_no_comma(doc.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eAHImfmw4G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_t = '''—Å—Ç–æ—Ä–æ–Ω—ã, –∏ –û–û–û ¬´–†–æ–º–∞—à–∫–∞¬ª –∏–º–µ–Ω—É–µ–º–æ–µ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´–ü–æ–∫—É–ø–∞—Ç–µ–ª—å¬ª, –≤ –ª–∏—Ü–µ –ü–µ—Ç—Ä–æ–≤–∞ –ü. –ü., –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞, —Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —Å–æ–≤–º–µ—Å—Ç–Ω–æ –∏–º–µ–Ω—É–µ–º—ã–µ ¬´–°—Ç–æ—Ä–æ–Ω—ã¬ª, –∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ - ¬´–°—Ç–æ—Ä–æ–Ω–∞¬ª, –∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä (–¥–∞–ª–µ–µ –ø–æ —Ç–µ–∫—Å—Ç—É ‚Äì –î–æ–≥–æ–≤–æ—Ä) –æ –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º'''\n",
        "test_find_agent_no_comma(_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQYazaVxdfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_full = '–ê–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –û–±—â–µ—Å—Ç–≤–æ ¬´–ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å ‚Äì –¢–µ—Ä–º–∏–Ω–∞–ª¬ª –∏–º–µ–Ω—É–µ–º–æ–µ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´–ü—Ä–æ–¥–∞–≤–µ—Ü¬ª, –≤ –ª–∏—Ü–µ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ ' \\\n",
        "               '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞, —Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –∏ –û–û–û ¬´–†–æ–º–∞—à–∫–∞¬ª, –∏–º–µ–Ω—É–µ–º–æ–µ –≤ ' \\\n",
        "               '–¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´–ü–æ–∫—É–ø–∞—Ç–µ–ª—å¬ª, –≤ –ª–∏—Ü–µ –ü–µ—Ç—Ä–æ–≤–∞ –ü.–ü., –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞, —Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —Å–æ–≤–º–µ—Å—Ç–Ω–æ ' \\\n",
        "               '–∏–º–µ–Ω—É–µ–º—ã–µ ¬´–°—Ç–æ—Ä–æ–Ω—ã¬ª, –∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ - ¬´–°—Ç–æ—Ä–æ–Ω–∞¬ª, –∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä (–¥–∞–ª–µ–µ –ø–æ —Ç–µ–∫—Å—Ç—É ‚Äì ' \\\n",
        "               '–î–æ–≥–æ–≤–æ—Ä) –æ –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º:'\n",
        "test_find_agent_no_comma(txt_full)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}