{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dev: Parse ALL contracts and save all to JSONs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "al6xZ5y6FBU1",
        "T9CRJ19ZAPyG",
        "B8DgCjtPAqKT"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemoware/analyser/blob/dev/notebooks/dev_Parse_ALL_contracts_and_save_all_to_JSONs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCAExPc0iE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document_parser_lib_version='1.1.4'\n",
        "_git_branch = 'dev'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGbb8gDSTvuW",
        "colab_type": "text"
      },
      "source": [
        "### Mount gDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7_rZoyzMRzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbsxFAqC6pjQ",
        "colab_type": "text"
      },
      "source": [
        "# Import code from gitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F89NLdN6A8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "!pip install overrides\n",
        "\n",
        "–ù–∏—á—Ç–æ = None\n",
        "\n",
        "\n",
        "\n",
        "def exec(x):\n",
        "  r = subprocess.check_output(x, shell=True)\n",
        "  r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "  print(r)\n",
        "\n",
        "\n",
        "print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "try:\n",
        "  exec('rm -r nlp_tools')\n",
        "except:\n",
        "  pass\n",
        "exec(f'git clone --single-branch --branch {_git_branch} https://github.com/nemoware/analyser.git nlp_tools')\n",
        "\n",
        "print('ü¶ä GIT revision:')\n",
        "exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "print('‚ù§Ô∏èimporting Code from GitHub ... DONE')\n",
        "\n",
        "\n",
        "#----\n",
        "import matplotlib as mpl\n",
        "from documents import TextMap\n",
        "from renderer import HtmlRenderer\n",
        "from legal_docs import DocumentJson\n",
        " \n",
        "\n",
        "class DemoRenderer(HtmlRenderer):\n",
        "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "    display(HTML(html))\n",
        "\n",
        "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "    return super()._to_color_text(tokens, weights, mpl, colormap=colormap, _range=_range)\n",
        "\n",
        "   \n",
        "renderer_ = DemoRenderer()\n",
        "\n",
        "def print_json_summary(cd:DocumentJson):\n",
        "  wordsmap = TextMap(cd.normal_text, cd.tokenization_maps['$words'])\n",
        "  print(f'read file {cd.filename}')\n",
        "\n",
        "  for tag in cd.tags:\n",
        "    span = tag.span\n",
        "    _map = cd.tokenization_maps[tag.span_map]\n",
        "    print(tag)\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPLjOzkOATgk",
        "colab_type": "text"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCfuE2dw6wO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import unittest\n",
        "import warnings\n",
        "\n",
        "!pip install pyjarowinkler\n",
        "\n",
        "from contract_parser import ContractAnlysingContext, ContractDocument\n",
        "from contract_patterns import ContractPatternFactory\n",
        "from documents import TextMap\n",
        "from legal_docs import LegalDocument\n",
        "from legal_docs import DocumentJson\n",
        "\n",
        "from ml_tools import SemanticTag, filter_values_by_key_prefix\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esxRGxnjidln",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " \n",
        "\n",
        "### Utilits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iceqc8qUjX8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_semantic_tag(tag: SemanticTag, map: TextMap):\n",
        "  print('-->', f'{tag.kind} \\t\\t [{tag.value}]\\t [{map.text_range(tag.span)}]')\n",
        "\n",
        "\n",
        "def print_json_summary(cd:DocumentJson):\n",
        "  wordsmap = TextMap(cd.normal_text, cd.tokenization_maps['$words'])\n",
        " \n",
        "  for tag in cd.tags:\n",
        "    if tag.kind !='headline':\n",
        "     print_semantic_tag(tag, wordsmap)\n",
        " \n",
        "\n",
        "\n",
        "def json2html(cd:DocumentJson):\n",
        "  wordsmap = TextMap(cd.normal_text, cd.tokenization_maps['words'])\n",
        "  markup_vector = np.zeros(len(wordsmap))\n",
        " \n",
        "  for tag in cd.attributes:\n",
        "    if 'span' in  cd.attributes[tag]:\n",
        "      span = cd.attributes[tag]['span']\n",
        "      confidence = cd.attributes[tag]['confidence']\n",
        "      markup_vector[span[0]:span[1]] += confidence\n",
        "    else:\n",
        "      warnings.warn(f'{tag} has no span')\n",
        "\n",
        "  return renderer_.to_color_text(wordsmap.tokens, markup_vector, _range=(0, 1))\n",
        "  \n",
        " \n",
        "def load_and_show_json(filename):\n",
        "  with open(filename, 'r') as json_file:\n",
        "    data_str = json_file.read()\n",
        "    # print(str(data_str))\n",
        "    json_obj:DocumentJson = DocumentJson.from_json( data_str)\n",
        "    html = json2html(json_obj)\n",
        "    display(HTML(html))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpHstfXIOVqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from embedding_tools import ElmoEmbedder\n",
        "elmo_embedder = ElmoEmbedder(module_url = 'https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz')\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from contract_parser import ContractAnlysingContext\n",
        "contractAnlysingContext = ContractAnlysingContext(elmo_embedder, renderer_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKMB4pkuu2wi",
        "colab_type": "text"
      },
      "source": [
        "### Init document-parser lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415zlWl16SLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib_version = document_parser_lib_version\n",
        "\n",
        "!wget https://github.com/nemoware/document-parser/releases/download/$lib_version/document-parser-$lib_version-distribution.zip\n",
        "!unzip document-parser-$lib_version-distribution.zip\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ ['documentparser']=f'/content/document-parser-{lib_version}'\n",
        "from integration.word_document_parser import WordDocParser, join_paragraphs\n",
        "wp = WordDocParser()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHfhy1BhMNfm",
        "colab_type": "text"
      },
      "source": [
        "# Export all contracts to JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClO8-VAuT63y",
        "colab_type": "text"
      },
      "source": [
        "#### Parse all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107CPsZglZ7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attempt = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dobawgyTEZ0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import hyperparams as hp\n",
        "\n",
        "codebasepath = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(hp.__file__)))\n",
        "expected = pd.read_csv ( os.path.join(codebasepath, 'vocab', 'contracts.validation.csv' ) )\n",
        "\n",
        "contracts_filename_prefix = '/content/gdrive/My Drive/GazpromOil/Contracts/'\n",
        "\n",
        "\n",
        "filenames = [os.path.join(contracts_filename_prefix, fn) for fn in expected['_id']]\n",
        "filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXnyIGsn68o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "attempt += 1\n",
        "dirname = '{0:%y.%m.%d}'.format(datetime.datetime.now())\n",
        "_out = f'/content/gdrive/My Drive/GazpromOil/–í—Å—è—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (shared)/JSONs/contracts-{dirname}-{attempt}/'\n",
        "!mkdir '$_out'\n",
        "print(_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r0dVpb76jay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import hyperparams as hp\n",
        " \n",
        "import math\n",
        "import numbers\n",
        "import decimal\n",
        "\n",
        "def validate_contracts():\n",
        "  codebasepath = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(hp.__file__)))\n",
        "  expected = pd.read_csv ( os.path.join(codebasepath, 'vocab', 'contracts.validation.csv' ) )\n",
        "  actual = pd.read_csv (   os.path.join(_out, 'contracts.validation.csv')  )\n",
        "\n",
        "  msgs = []\n",
        "  errors = 0\n",
        "  def _check(key, e, a, col)->int:\n",
        "    _x1 = e[col]\n",
        "    _x2 = a[col]    \n",
        "    if (isinstance(_x1, numbers.Number) and  math.isnan(_x1)) and (isinstance(_x2, numbers.Number) and math.isnan(_x2)):\n",
        "      return 0\n",
        "    if _x1 != _x2:\n",
        "      msg = f\"{key}:\\t{col} \\n\\t expected: '{e[col]}' \\n\\t   ACTUAL: '{a[col]}'\"\n",
        "      msgs.append(msg)\n",
        "      return 1\n",
        "    return 0\n",
        "  \n",
        "  for x in actual['_id']:\n",
        "    r1 = expected [ expected ['_id'] == x ].iloc[0]\n",
        "    r2 = actual [ actual ['_id'] == x ].iloc[0]\n",
        "\n",
        "    errors += _check( x, r1, r2, 'org_1_name' )\n",
        "    errors += _check( x, r1, r2, 'org_2_name' )\n",
        "    errors += _check( x, r1, r2, 'value' )\n",
        "    errors += _check( x, r1, r2, 'subject' )\n",
        "    \n",
        "  print('='*100)\n",
        "  print('^'*100)\n",
        "  print (f\"ERRRORS: \\t{errors} of {len(actual)} docs\")\n",
        "\n",
        "\n",
        "  with open(os.path.join(_out, 'errors.txt') , 'w') as the_file:\n",
        "    for m in msgs:\n",
        "      the_file.write( m + '\\n')\n",
        "\n",
        "    the_file.write('^'*100)\n",
        "    the_file.write(f\"\\nERRRORS: \\t{errors} of {len(actual)} docs\")\n",
        "    print (f'errors saved to {the_file}')\n",
        "  return msgs\n",
        "\n",
        "def __attr_val(d, a):\n",
        "  if a in d:\n",
        "    return d[a]['value']\n",
        "\n",
        "def to_csv(filenames_to_jsons):\n",
        "\n",
        "  df = pd.DataFrame(columns=( '_id', 'value', 'org_1_name', 'org_2_name', 'subject')) \n",
        "\n",
        "  i=0\n",
        "  for fn in filenames_to_jsons.keys():\n",
        "    for json_fn in filenames_to_jsons[fn]:\n",
        "      # print(json_fn)\n",
        "      with open(json_fn, 'r') as json_file:\n",
        "        data_str = json_file.read()\n",
        "        json_obj:DocumentJson = DocumentJson.from_json( data_str)\n",
        "        # _id =os.path.relpath( json_obj._id, contracts_filename_prefix )\n",
        "        _id = json_obj._id\n",
        "        df.loc[i] =[ _id,  \n",
        "                      __attr_val(json_obj.attributes, 'value'),\n",
        "                      __attr_val(json_obj.attributes, 'org_1_name'),\n",
        "                      __attr_val(json_obj.attributes, 'org_2_name'),\n",
        "                      __attr_val(json_obj.attributes, 'subject')] \n",
        "        i+=1\n",
        " \n",
        "  \n",
        "  df.to_csv(os.path.join(_out,  'contracts.validation.csv'), encoding='utf-8', index=False)\n",
        "  return df\n",
        "\n",
        "\n",
        "# validate_contracts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUASEb5sMxJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from legal_docs import DocumentJson\n",
        "\n",
        "hp.HyperParameters.subsidiary_name_match_min_jaro_similarity = 0.9\n",
        "#filenames = list (wp.list_filenames(contracts_filename_prefix))[0:30]\n",
        "# filenames = ['/content/gdrive/My Drive/GazpromOil/Contracts/3 —ç—Ç–∞–ø –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º/–¥–æ–≥–æ–≤–æ—Ä.10.docx']\n",
        "\n",
        "\n",
        "cnt = 0\n",
        "k=0\n",
        "filenames_to_jsons={}\n",
        "for fn in filenames:\n",
        "  filenames_to_jsons[fn] = []\n",
        "  cnt += 1\n",
        "  print(f'reading:\"{fn}\"')\n",
        "  short_fn = fn.split('/')[-1]\n",
        "\n",
        "  try:\n",
        "    # ------------------------\n",
        "    results = wp.read_doc(fn)\n",
        "    k=0\n",
        "    for doc in results['documents'][:1]: #XXX\n",
        "      k+=1\n",
        "      if 'CONTRACT'== doc['documentType']:\n",
        "        contract_id = os.path.relpath( fn, contracts_filename_prefix )\n",
        "        contract = join_paragraphs(doc, contract_id)\n",
        "        # ------------------------\n",
        "\n",
        "        contractAnlysingContext.analyze_contract_doc(contract)\n",
        "        contract = contractAnlysingContext.contract\n",
        "      \n",
        "        _path =  os.path.join(_out, f'{k}-{short_fn}.json')\n",
        "        with open(_path, 'w') as file:          \n",
        "          # \n",
        "          jjj = DocumentJson(contract)\n",
        "          file.write(jjj.dumps())\n",
        "          filenames_to_jsons[fn].append(_path)                    \n",
        "          print(f'=== üìÇsaved file to {_path}')\n",
        "          print('='*100)\n",
        "\n",
        "        to_csv(filenames_to_jsons) #TODO: do not read all here\n",
        "        validate_contracts()\n",
        "  except Exception as e:\n",
        "    print(e)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7RbXrF1HE-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames_to_jsons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ-RseLd9e_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "normal_name = '–û–û–û ¬´—á—Ç–æ-—Ç–æ ¬´–∫–∞–∫-—Ç–æ¬ª'\n",
        "re.sub(r'(¬´?<=(.*?¬´.*?¬ª))', '?REPL', normal_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJQac-Z5FqMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = to_csv(filenames_to_jsons)\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML(df.to_html(index=False)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-cATHm_btEt",
        "colab_type": "text"
      },
      "source": [
        "# üëå Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdL0Wu-SCZ5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_contracts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuCvVLMRZvjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual = pd.read_csv (  'contracts.validation.csv'  )\n",
        "actual[actual['_id']=='3 —ç—Ç–∞–ø –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º/O_final.docx'].iloc[0]['org_1_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aZ4HQRstCLH",
        "colab_type": "text"
      },
      "source": [
        "### Verify random json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIHEi_QqtGS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_json_file = os.path.join(_out,filenames[3]).split('/')[-1]+'.json'\n",
        "test_json_file = '/content/gdrive/My Drive/GazpromOil/–í—Å—è—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (shared)/JSONs/contracts-19.10.17-4/1-! –î–æ–≥–æ–≤–æ—Ä _1.docx.json'\n",
        "test_json_file = '/content/gdrive/My Drive/GazpromOil/–í—Å—è—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (shared)/JSONs/contracts-19.10.24-4/1-–î_–ò.docx.json'\n",
        "load_and_show_json(test_json_file)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19diMBJejNZ",
        "colab_type": "text"
      },
      "source": [
        "#Parse 2K sectioned contracts (Achtung, dis takes time)\n",
        "- upload zipped results of document-parser first "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxlAyKnbh4O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzNVR7Kee5mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/jsons_phase0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1d3bop-fyqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "filenames = [file for file in glob.glob( \"/content/jsons_phase0/**/*.json\", recursive=True)] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUwOn_EstJeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPkY14L71ieD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import csv, json\n",
        "from bson import json_util\n",
        "\n",
        "\n",
        "from contract_parser import ContractAnlysingContext\n",
        "from integration.word_document_parser import join_paragraphs\n",
        "\n",
        "\n",
        "def export_csv(rows, headline=['1', '2', '3', '4', '5', '6', '7', '8', '9']):\n",
        "  with open(f'contracts-stats.csv', mode='w') as csv_file:\n",
        "    _writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    _writer.writerow(headline)\n",
        "    for l in rows:\n",
        "      _writer.writerow(l)\n",
        "\n",
        "\n",
        "def _parse_contract(res, doc_id, row, ctx: ContractAnlysingContext):\n",
        "  contract = join_paragraphs(res, doc_id)\n",
        "  ctx.analyze_contract_doc(contract)\n",
        "\n",
        "  row[4:8] = [contract.tag_value('org.1.name'),\n",
        "              contract.tag_value('org.1.alias'),\n",
        "              contract.tag_value('org.2.name'),\n",
        "              contract.tag_value('org.2.alias')]\n",
        "  return contract\n",
        "\n",
        " \n",
        "rows=[]\n",
        "cnt=0\n",
        "\n",
        "for fn in filenames[200:]:\n",
        "  with open(fn, 'r') as file:\n",
        "    json_string = file.read()\n",
        "    res = json.loads(json_string, object_hook=json_util.object_hook)\n",
        "\n",
        "  if 'CONTRACT' == res[\"documentType\"]:\n",
        "    row = [cnt, '', None, None, None, None, None, None, fn, None]\n",
        "    row[2:4] = [res[\"documentType\"], res[\"documentDate\"]]\n",
        "    contract = _parse_contract(res, fn,  row, contractAnlysingContext)\n",
        "         \n",
        "    short_fn = fn.split('/')[-1]\n",
        "    with open(f'/content/out/{short_fn}.json', 'w') as file:\n",
        "      jjj = DocumentJson(contract)\n",
        "      file.write(jjj.dumps())\n",
        "\n",
        "\n",
        "    rows.append(row)\n",
        "    if cnt % 5 == 0: #save every 5 rows\n",
        "      export_csv(rows)\n",
        "\n",
        "  cnt+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoWC-mK1zwlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qln4vihrY9gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def zipfolder(foldername, target_dir):            \n",
        "  zipobj = zipfile.ZipFile(foldername + '.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "  rootlen = len(target_dir) + 1\n",
        "  for base, dirs, files in os.walk(target_dir):\n",
        "    for file in files:\n",
        "      fn = os.path.join(base, file)\n",
        "      zipobj.write(fn, fn[rootlen:])\n",
        "\n",
        "\n",
        "\n",
        "zipfolder('out','/content/out')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}