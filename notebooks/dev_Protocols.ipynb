{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dev Protocols.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "0n-DlKATL2JQ",
        "WPEjJV3Elb8t",
        "IoDRgHbFkdPL",
        "Aejr-po6QVeZ",
        "q58BgdvHanlN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJjbZeN6Pbtx",
        "colab_type": "text"
      },
      "source": [
        "# PROTOCOLS analyse \n",
        "## Instruction:\n",
        "1. On the left-side panel, change to Files tab \n",
        "2. Upload a protocol file\n",
        "3. Right click on the uploaded file -> copy path\n",
        "2. Enter (paste) its path/name into the 'Read doc' form below\n",
        "3. top menu: Runtime/run all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQnl3VnQZQML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_git_branch = 'charters-subjects-2'\n",
        "\n",
        "#Document parser, refer https://github.com/nemoware/document-parser/releases\n",
        "lib_version = '1.1.18'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n-DlKATL2JQ",
        "colab_type": "text"
      },
      "source": [
        "# INIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPEjJV3Elb8t",
        "colab_type": "text"
      },
      "source": [
        "## pull code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPFNIoGZL198",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from IPython.core.display import display, HTML\n",
        "from google.colab import files\n",
        "\n",
        "!pip install overrides\n",
        "!pip install pyjarowinkler\n",
        "\n",
        "–ù–∏—á—Ç–æ = None\n",
        "\n",
        "\n",
        "\n",
        "def exec(x):\n",
        "  r = subprocess.check_output(x, shell=True)\n",
        "  r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "  print(r)\n",
        "\n",
        "\n",
        "print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "try:\n",
        "  exec('rm -r nlp_tools')\n",
        "except:\n",
        "  pass\n",
        "exec(f'git clone --single-branch --branch {_git_branch} https://github.com/nemoware/analyser.git nlp_tools')\n",
        "\n",
        "print('ü¶ä GIT revision:')\n",
        "exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "print('‚ù§Ô∏èimporting Code from GitHub ... DONE')\n",
        "\n",
        "\n",
        "#----\n",
        "import matplotlib as mpl\n",
        "from analyser.documents import TextMap\n",
        "from analyser.legal_docs import DocumentJson\n",
        "from colab_support.renderer import HtmlRenderer\n",
        "\n",
        " \n",
        "\n",
        "class DemoRenderer(HtmlRenderer):\n",
        "  def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
        "    html = self.to_color_text(tokens, weights, colormap, print_debug, _range, separator=separator)\n",
        "    display(HTML(html))\n",
        "\n",
        "  def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None, separator=' '):\n",
        "    return super()._to_color_text(tokens, weights, mpl, colormap=colormap, _range=_range, separator=separator)\n",
        "\n",
        "   \n",
        "renderer_ = DemoRenderer()\n",
        "\n",
        "def print_json_summary(cd:DocumentJson):\n",
        "  wordsmap = TextMap(cd.normal_text, cd.tokenization_maps['$words'])\n",
        "  print(f'read file {cd.filename}')\n",
        "\n",
        "  for tag in cd.tags:\n",
        "    span = tag.span\n",
        "    _map = cd.tokenization_maps[tag.span_map]\n",
        "    print(tag)\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_mlpzzdNAWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyjarowinkler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKMB4pkuu2wi",
        "colab_type": "text"
      },
      "source": [
        "### Init document-parser lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415zlWl16SLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "if not os.path.isfile(f'document-parser-{lib_version}-distribution.zip'):\n",
        "  !wget https://github.com/nemoware/document-parser/releases/download/$lib_version/document-parser-$lib_version-distribution.zip\n",
        "if not os.path.isdir(f'document-parser-{lib_version}'):\n",
        "  !unzip document-parser-$lib_version-distribution.zip\n",
        "\n",
        " \n",
        "os.environ ['documentparser']=f'/content/document-parser-{lib_version}'\n",
        "from integration.word_document_parser import WordDocParser, join_paragraphs\n",
        "wp = WordDocParser()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNmYb03dFcJ9",
        "colab_type": "text"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fbSX2h2MedM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import unittest\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from analyser.contract_parser import ContractAnlysingContext, ContractDocument\n",
        "from analyser.contract_patterns import ContractPatternFactory\n",
        "from analyser.legal_docs import LegalDocument\n",
        " \n",
        "from analyser.ml_tools import *\n",
        "\n",
        "# from headers_detector import doc_features, load_model, make_headline_attention_vector\n",
        "from analyser.hyperparams import HyperParameters\n",
        "from analyser.protocol_parser import protocol_votes_re\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCveVZqvNhsr",
        "colab_type": "text"
      },
      "source": [
        "## üíÖ Init Embedder(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3k194xUFy20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from protocol_parser import  ProtocolPatternFactory\n",
        "from tf_support.embedder_elmo import ElmoEmbedder\n",
        "# from contract_patterns import ContractPatternFactory\n",
        "elmo_embedder = ElmoEmbedder()\n",
        "elmo_embedder_default = ElmoEmbedder(layer_name=\"default\")\n",
        "\n",
        "# protocols_factory = ProtocolPatternFactory(elmo_embedder)\n",
        "# contracts_factory = ContractPatternFactory(elmo_embedder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to0MzdyWjEWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from analyser.contract_parser import find_value_sign_currency_attention\n",
        "from analyser.legal_docs import tokenize_doc_into_sentences_map, ContractValue\n",
        "from analyser.ml_tools import *\n",
        "from analyser.parsing import ParsingContext\n",
        "from analyser.patterns import *\n",
        "from analyser.protocol_parser import ProtocolDocument, find_confident_spans, protocol_votes_re, ProtocolPatternFactory\n",
        "from analyser.protocol_parser import  find_org_structural_level, find_protocol_org, ProtocolParser\n",
        "from analyser.text_tools import *\n",
        "\n",
        "# legal_docs.py\n",
        "from tf_support.embedder_elmo import ElmoEmbedder\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2ttjnsaMC3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "protocol_analyser = ProtocolParser(elmo_embedder, elmo_embedder_default)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDRIF48ks3OV",
        "colab_type": "text"
      },
      "source": [
        "# Read doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waeVpcnaLgEJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Enter uploaded file path\n",
        "\n",
        "filename = '/content/6. \\u041F\\u0440\\u043E\\u0442\\u043E\\u043A\\u043E\\u043B_\\u041D\\u0435\\u0434\\u0432\\u0438\\u0436\\u0438\\u043C\\u043E\\u0441\\u0442\\u044C.docx' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "results = wp.read_doc(filename)\n",
        "for doc in results['documents'][:1]:  # XXX\n",
        "  if 'PROTOCOL' == doc['documentType']:    \n",
        "    doc = join_paragraphs(doc, 'no_id')\n",
        "\n",
        "\n",
        "for p in doc.paragraphs:\n",
        "  print ('‚ò¢Ô∏è', p.header.value.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEgJ63pck0tM",
        "colab_type": "text"
      },
      "source": [
        "# üß† Analyse PHASE 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrQOg1UimOtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =====================================\n",
        "from analyser.parsing import AuditContext\n",
        "actx = AuditContext()\n",
        "protocol_analyser.find_org_date_number(doc, actx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aejr-po6QVeZ",
        "colab_type": "text"
      },
      "source": [
        "### render PHASE 0 results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEYJEzygQO9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in doc.get_tags():\n",
        "  print(t)\n",
        "renderer_.render_color_text(doc.tokens,  doc.get_tags_attention() )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUIhU4cCQhRx",
        "colab_type": "text"
      },
      "source": [
        "# üß†Analyse PHASE 1 \n",
        "(requires phase 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr733JbFQj4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "protocol_analyser.find_attributes(doc, actx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtldMdmoQpj-",
        "colab_type": "text"
      },
      "source": [
        "### render PHASE 1 results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzPEiquCFEx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in doc.get_tags():\n",
        "  print(t)\n",
        "renderer_.render_color_text(doc.tokens,  doc.get_tags_attention() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylTE3isTYq7e",
        "colab_type": "text"
      },
      "source": [
        "# save to JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNG4G5_RY7d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fn =  f'{filename}.json'\n",
        "print('saving JSON to', fn)\n",
        "\n",
        "with open(fn, 'w') as file:\n",
        "  jjj = DocumentJson(doc)\n",
        "  file.write(jjj.dumps())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsMYnR_WKjpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc.to_json_obj()['attributes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBlILIQ0asrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raise('STOP HERE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFBzr6huCJh-",
        "colab_type": "text"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uKRCfMCMK0",
        "colab_type": "text"
      },
      "source": [
        "## Sections attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjAMCD52CPNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "protocol_sections_edges = protocol_analyser.find_protocol_sections_edges(doc.distances_per_sentence_pattern_dict)\n",
        "renderer_.render_color_text(doc.sentence_map.tokens,  protocol_sections_edges , _range=[0,1], separator='¬∂<br>')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ5ztxb3YHfj",
        "colab_type": "text"
      },
      "source": [
        "### sections spans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHuaLeIOY7RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from analyser.documents import sentences_attention_to_words\n",
        "from analyser.dates import   document_number_c\n",
        "from analyser.contract_agents import complete_re as agents_re\n",
        "from analyser.transaction_values import complete_re as values_re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5-21a9vYz-",
        "colab_type": "text"
      },
      "source": [
        "### AV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk_QuRBqaBBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#DEAL APPROVAL SENTENCES\n",
        "v_deal_approval = max_exclusive_pattern_by_prefix(doc.distances_per_sentence_pattern_dict, 'deal_approval_')\n",
        "_spans, deal_approval_av = sentences_attention_to_words(v_deal_approval, doc.sentence_map,\n",
        "                                                                        doc.tokens_map)\n",
        "deal_approval_relu_av = best_above(deal_approval_av, 0.5)\n",
        "\n",
        "# VOTES\n",
        "votes_av = doc.tokens_map.regex_attention(protocol_votes_re)\n",
        "# DOC NUMBERS\n",
        "numbers_av = doc.tokens_map.regex_attention(document_number_c)\n",
        "# DOC AGENTS orgs\n",
        "agents_av = doc.tokens_map.regex_attention(agents_re)\n",
        "\n",
        "# DOC MARGIN VALUES\n",
        "margin_values_av = protocol_analyser._get_value_attention_vector(doc)\n",
        "margin_values_v = doc.tokens_map.regex_attention(values_re)\n",
        "margin_values_v*=margin_values_av\n",
        "\n",
        "\n",
        "renderer_.render_color_text(doc.tokens,  deal_approval_relu_av , _range=[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-hlVQgoZz03",
        "colab_type": "text"
      },
      "source": [
        "## Combined attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5rRAeNxZ37F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_av = sum_probabilities([deal_approval_relu_av,\n",
        "                                 margin_values_v, \n",
        "                                 agents_av/2,\n",
        "                                 votes_av/2, \n",
        "                                 numbers_av/2])\n",
        "\n",
        "\n",
        "combined_av_norm = combined_av = best_above(combined_av, 0.2) \n",
        "renderer_.render_color_text(doc.tokens,  combined_av_norm , _range=[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0kEkf60fpDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# v_sections_attention = find_protocol_sections_edges(protocol_analyser, doc.distances_per_sentence_pattern_dict)\n",
        "\n",
        "_question_spans_sent = spans_between_non_zero_attention(protocol_sections_edges)\n",
        "question_spans_words = doc.sentence_map.remap_slices(_question_spans_sent, doc.tokens_map)\n",
        "agenda_questions = list(find_confident_spans(question_spans_words, combined_av_norm, 'agenda_item', 0.5))\n",
        "\n",
        "for x in agenda_questions:\n",
        "  print(\"=\"*100)\n",
        "  print(x)\n",
        "  print(doc.substr(x))\n",
        "\n",
        "for span in question_spans_words:\n",
        "  print(\"=\"*100)\n",
        "  sl=slice(span[0],span[1])\n",
        "  renderer_.render_color_text(doc[sl].tokens,  combined_av_norm[sl] , _range=[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ5aMD3mVB3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raise ('stop here please for now')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Gv_KvT69cR",
        "colab_type": "text"
      },
      "source": [
        "## Debug votes finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjJBz6R1-SVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from analyser.protocol_parser import ProtocolAV\n",
        "renderer_.render_color_text(doc.tokens,  doc.distances_per_pattern_dict[ProtocolAV.bin_votes_attention.name] , _range=[0,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqiAalo_UYhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "renderer_.render_color_text(doc.tokens, numbers_av+votes_av, _range=[0,2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce204cJH-S_N",
        "colab_type": "text"
      },
      "source": [
        "### debug protocol_votes_re"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UheBuqWQ-E6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = protocol_votes_re.search(doc.text)\n",
        "\n",
        "match = doc.text[x.span()[0]:x.span()[1]]\n",
        "print(f'[{match}]')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbpLHXne-Vzs",
        "colab_type": "text"
      },
      "source": [
        "### debug spans_having_votes_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJ-oVXP-hmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_sections_attention = protocol_analyser.find_protocol_sections_edges(doc.distances_per_sentence_pattern_dict)\n",
        "question_spans_sent = spans_between_non_zero_attention(v_sections_attention)\n",
        "question_spans_words = doc.sentence_map.remap_slices(question_spans_sent, doc.tokens_map)\n",
        "\n",
        "for c in question_spans_words:\n",
        "  print('-'*80)\n",
        "  print (c, doc.tokens_map.text_range(c))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}